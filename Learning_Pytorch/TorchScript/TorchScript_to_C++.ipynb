{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TorchScript_to_C++.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmS8bSl2OEc8",
        "colab_type": "text"
      },
      "source": [
        "# Loading a TorchScript Model in C++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WriaTgCxOLoq",
        "colab_type": "text"
      },
      "source": [
        "For production scenarios, C++ is very often the language of choice, even if only to bind it into another language like Java, Rust or Go. The following paragraphs will outline the path PyTorch provides to go from an existing Python model to a serialized representation that can be loaded and executed purely from C++, with no dependency on Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysPJRN6DOiic",
        "colab_type": "text"
      },
      "source": [
        "# Step 1: Converting Your PyTorch Model to Torch Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K6S0lThOl_J",
        "colab_type": "text"
      },
      "source": [
        "A PyTorch model’s journey from Python to C++ is enabled by Torch Script, a representation of a PyTorch model that can be understood, compiled and serialized by the Torch Script compiler. If you are starting out from an existing PyTorch model written in the vanilla “eager” API, you must first convert your model to Torch Script. In the most common cases, discussed below, this requires only little effort. \n",
        "\n",
        "If you already have a Torch Script module, you can skip to the next section of this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYknOUi0OpEM",
        "colab_type": "text"
      },
      "source": [
        "There exist two ways of converting a PyTorch model to Torch Script. \n",
        "\n",
        "The first is known as tracing, a mechanism in which the structure of the model is captured by evaluating it once using example inputs, and recording the flow of those inputs through the model. \n",
        "\n",
        "This is suitable for models that make limited use of control flow. \n",
        "\n",
        "The second approach is to add explicit annotations to your model that inform the Torch Script compiler that it may directly parse and compile your model code, subject to the constraints imposed by the Torch Script language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3pw0dZ_OvQa",
        "colab_type": "text"
      },
      "source": [
        "# Tracing and getting a TorchScript Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qKcD3RWO2AN",
        "colab_type": "text"
      },
      "source": [
        "To convert a PyTorch model to Torch Script via tracing, you must pass an instance of your model along with an example input to the torch.jit.trace function. \n",
        "\n",
        "This will produce a torch.jit.ScriptModule object with the trace of your model evaluation embedded in the module’s forward method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9WD2QfpKuLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nZD4UKAO7Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torchvision.models.resnet18()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_arqbrxO72Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An example input you would normally provide to your model's forward() method.\n",
        "example = torch.rand(1, 3, 224, 224)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5upv2tUO92z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
        "traced_script_module = torch.jit.trace(model, example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrZryGNtPIvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(traced_script_module)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbduLjJaPO2h",
        "colab_type": "text"
      },
      "source": [
        "# Converting to Torch Script via Annotation (Scripting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXc0I4LdPSqs",
        "colab_type": "text"
      },
      "source": [
        "Under certain circumstances, such as if your model employs particular forms of control flow, you may want to write your model in Torch Script directly and annotate your model accordingly. For example, say you have the following vanilla Pytorch model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNocXtJ2PL5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModule(torch.nn.Module):\n",
        "    def __init__(self, N, M):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.sum() > 0:\n",
        "          output = self.weight.mv(input)\n",
        "        else:\n",
        "          output = self.weight + input\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmLINBfUPXp1",
        "colab_type": "text"
      },
      "source": [
        "Because the forward method of this module uses control flow that is dependent on the input, it is not suitable for tracing. \n",
        "\n",
        "Instead, we can convert it to a ScriptModule. In order to convert the module to the ScriptModule, one needs to compile the module with torch.jit.script as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSh1puKQPUDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModule(torch.nn.Module):\n",
        "    def __init__(self, N, M):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.sum() > 0:\n",
        "          output = self.weight.mv(input)\n",
        "        else:\n",
        "          output = self.weight + input\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWUxB3rcPaXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_module = MyModule(10,20)\n",
        "sm = torch.jit.script(my_module)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnjV4sjIPiQI",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Serializing Your Script Module to a File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQRtz9vXPqxk",
        "colab_type": "text"
      },
      "source": [
        "Once you have a ScriptModule in your hands, either from tracing or annotating a PyTorch model, you are ready to serialize it to a file. \n",
        "\n",
        "Later on, you’ll be able to load the module from this file in C++ and execute it without any dependency on Python. \n",
        "\n",
        "Say we want to serialize the ResNet18 model shown earlier in the tracing example. To perform this serialization, simply call save on the module and pass it a filename:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWxS_TOJPdhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traced_script_module.save(\"traced_resnet_model.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMj3KB8SP5Yd",
        "colab_type": "text"
      },
      "source": [
        "This will produce a traced_resnet_model.pt file in your working directory. If you also would like to serialize my_module, call my_module.save(\"my_module_model.pt\") \n",
        "\n",
        "We have now officially left the realm of Python and are ready to cross over to the sphere of C++."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1lyqsCQLb6",
        "colab_type": "text"
      },
      "source": [
        "# Step 3: Loading Your Script Module in C++\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYi_PQ70QNYa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "To load your serialized PyTorch model in C++, your application must depend on the PyTorch C++ API – also known as LibTorch. \n",
        "\n",
        "The LibTorch distribution encompasses a collection of shared libraries, header files and CMake build configuration files. \n",
        "\n",
        "While CMake is not a requirement for depending on LibTorch, it is the recommended approach and will be well supported into the future. \n",
        "\n",
        "For this tutorial, we will be building a minimal C++ application using CMake and LibTorch that simply loads and executes a serialized PyTorch model."
      ]
    }
  ]
}