{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deploying_Flask_on_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBKRpps4BFvv",
        "colab_type": "text"
      },
      "source": [
        "# Deploying on Flask with Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W__nlMywA907",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj9dMJvzBUJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "23465de4-f0b8-4f33-bdc2-6dd93531b727"
      },
      "source": [
        "import socket\n",
        "print(socket.gethostbyname(socket.gethostname()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNs9FzNEBZ3t",
        "colab_type": "text"
      },
      "source": [
        "# Running Flask as a Background Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLjAsiQ-BZcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "02b7139b-2f22-4a30-8d5b-c70e6606cb41"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from flask import Flask, jsonify, make_response, request\n",
        "import threading\n",
        "\n",
        "app = Flask(__name__)\n",
        "padding_size = 1000\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/sentiment_model/sentiment_analysis.hdf5')\n",
        "text_encoder = tfds.features.text.TokenTextEncoder.load_from_file(\"/content/drive/My Drive/sentiment_model/sa_encoder.vocab\")\n",
        "\n",
        "print('Model and Vocabalory loaded.......')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model and Vocabalory loaded.......\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ym3AUZZBnj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    return \"I am alive!\"\n",
        "\n",
        "def pad_to_size(vec, size):\n",
        "    zeros = [0] * (size - len(vec))\n",
        "    vec.extend(zeros)\n",
        "    return vec\n",
        "\n",
        "def predict_fn(predict_text, pad_size):\n",
        "    encoded_text = text_encoder.encode(predict_text)\n",
        "    encoded_text = pad_to_size(encoded_text, pad_size)\n",
        "    encoded_text = tf.cast(encoded_text, tf.int64)\n",
        "    predictions = model.predict(tf.expand_dims(encoded_text, 0))\n",
        "\n",
        "    return (predictions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsNVBvjNER0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@app.route('/seclassifier', methods=['POST'])\n",
        "def predict_sentiment():\n",
        "    text = request.get_json()['text']\n",
        "    print(text)\n",
        "    predictions = predict_fn(text, padding_size)\n",
        "    sentiment = 'positive' if float(''.join(map(str,predictions[0]))) > 0 else 'Negative'\n",
        "    return jsonify({'predictions ':predictions, 'sentiment ': sentiment})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkmhSpXrEWve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "6bfca0db-3ece-424f-da1a-5914ca203352"
      },
      "source": [
        "threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':6000}).start()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0.0.0.0:6000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_8N-fPNEdGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "8e6698f0-0601-4f0e-d772-3590b4559238"
      },
      "source": [
        "import requests\n",
        "req = requests.get(\"http://172.28.0.2:6000/\")\n",
        "print(req.status_code)\n",
        "print(req.text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [10/Jun/2020 17:15:03] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "I am alive!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvYOMKssOl2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f22e7811-c371-4e50-ae82-39ada6ed71d3"
      },
      "source": [
        "import requests, json\n",
        "headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
        "data = {\"text\":\"Still working my way through it but definitely changes your view on investment. Wish it was available on Audible\"}\n",
        "req = requests.post(\"http://172.28.0.2:6000/seclassifier\",  data=json.dumps(data), headers=headers)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Still working my way through it but definitely changes your view on investment. Wish it was available on Audible\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [10/Jun/2020 17:15:17] \"\u001b[37mPOST /seclassifier HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKSXusegOo4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "5d49bbca-8dd1-465f-dbb3-f32cb8bbd434"
      },
      "source": [
        "print(req.status_code)\n",
        "print(req.text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "{\"predictions \":[[0.8370056748390198]],\"sentiment \":\"positive\"}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIo69olbOr61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2832a8eb-65c0-40de-a248-372a1a1bd080"
      },
      "source": [
        "headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
        "data = {\"text\":\"I thought this will be good one. But I was wrong\"}\n",
        "req = requests.post(\"http://172.28.0.2:6000/seclassifier\",  data=json.dumps(data), headers=headers)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I thought this will be good one. But I was wrong\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [10/Jun/2020 17:15:45] \"\u001b[37mPOST /seclassifier HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg0vtNvMOvwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "016b6886-8970-4433-cb7c-59e4835a9d59"
      },
      "source": [
        "print(req.status_code)\n",
        "print(req.text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "{\"predictions \":[[-0.8676939606666565]],\"sentiment \":\"Negative\"}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn6aKkszO34E",
        "colab_type": "text"
      },
      "source": [
        "# Running Flask as a External Server using ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRLlJg5MO3qV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9059b96c-f71c-4ee3-9bff-a8768635d0e1"
      },
      "source": [
        "import flask\n",
        "flask.__version__"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y1RvGo9OwT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip -q install flask-ngrok"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtIEnb2hRJ8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9ad8bd18-9979-42a2-e841-0b7ad9acbd8c"
      },
      "source": [
        "\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from flask import Flask, jsonify, make_response, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "padding_size = 1000\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/sentiment_model/sentiment_analysis.hdf5')\n",
        "text_encoder = tfds.features.text.TokenTextEncoder.load_from_file(\"/content/drive/My Drive/sentiment_model/sa_encoder.vocab\")\n",
        "\n",
        "print('Model and Vocabalory loaded.......')\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    return \"I am alive!\"\n",
        "\n",
        "def pad_to_size(vec, size):\n",
        "    zeros = [0] * (size - len(vec))\n",
        "    vec.extend(zeros)\n",
        "    return vec\n",
        "\n",
        "\n",
        "def predict_fn(predict_text, pad_size):\n",
        "    encoded_text = text_encoder.encode(predict_text)\n",
        "    encoded_text = pad_to_size(encoded_text, pad_size)\n",
        "    encoded_text = tf.cast(encoded_text, tf.int64)\n",
        "    predictions = model.predict(tf.expand_dims(encoded_text, 0))\n",
        "\n",
        "    return (predictions.tolist())\n",
        "\n",
        "\n",
        "@app.route('/seclassifier', methods=['POST'])\n",
        "def predict_sentiment():\n",
        "    text = request.get_json()['text']\n",
        "    print(text)\n",
        "    predictions = predict_fn(text, padding_size)\n",
        "    sentiment = 'positive' if float(''.join(map(str,predictions[0]))) > 0 else 'Negative'\n",
        "    return jsonify({'predictions ':predictions, 'sentiment ': sentiment})\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model and Vocabalory loaded.......\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZQLbeQCRaxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "51b21eb1-8926-44b3-bf85-9c0ce59207b1"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://214dd9884363.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [10/Jun/2020 17:30:27] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [10/Jun/2020 17:30:27] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}