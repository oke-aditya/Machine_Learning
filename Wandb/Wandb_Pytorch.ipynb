{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wandb_Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6809f5dfd2a4d59b42c508cab9590d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_250290bee6a544ebbe555280bb56a0e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7270672815a6415bbb58fac758792ff8",
              "IPY_MODEL_e8f720376e8b4812af9f8099d772e548"
            ]
          }
        },
        "250290bee6a544ebbe555280bb56a0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7270672815a6415bbb58fac758792ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ba46186945c45cb83071e468648073a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0d0740ed5e1416f9949815c7590be33"
          }
        },
        "e8f720376e8b4812af9f8099d772e548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_827727374e654121b0aa7403f97b369e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:09&lt;00:00, 18726783.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0b48b247a884fea9b9da1297a90293a"
          }
        },
        "4ba46186945c45cb83071e468648073a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0d0740ed5e1416f9949815c7590be33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "827727374e654121b0aa7403f97b369e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0b48b247a884fea9b9da1297a90293a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuHBa1Shto5L",
        "colab_type": "text"
      },
      "source": [
        "# Working with WandB and PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K3HBWwnvFy7",
        "colab_type": "text"
      },
      "source": [
        "## Initialize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBxFPmNitopd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No47NlZ4tlj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import random # to set the python random seed\n",
        "import numpy # to set the numpy random seed\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# WandB â€“ Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5HyxwXmtwNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WandB â€“ Login to your wandb account so you can log all your metrics\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sf3H6zavDVF",
        "colab_type": "text"
      },
      "source": [
        "## Create a simple NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ5VTzcCuzih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # In our constructor, we define our neural network architecture that we'll use in the forward pass.\n",
        "        # Conv2d() adds a convolution layer that generates 2 dimensional feature maps to learn different aspects of our image\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        \n",
        "        # Linear(x,y) creates dense, fully connected layers with x inputs and y outputs\n",
        "        # Linear layers simply output the dot product of our inputs and weights.\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Here we feed the feature maps from the convolutional layers into a max_pool2d layer.\n",
        "        # The max_pool2d layer reduces the size of the image representation our convolutional layers learnt,\n",
        "        # and in doing so it reduces the number of parameters and computations the network needs to perform.\n",
        "        # Finally we apply the relu activation function which gives us max(0, max_pool2d_output)\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        \n",
        "        # Reshapes x into size (-1, 16 * 5 * 5) so we can feed the convolution layer outputs into our fully connected layer\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        \n",
        "        # We apply the relu activation function and dropout to the output of our fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        # Finally we apply the softmax function to squash the probabilities of each class (0-9) and ensure they add to 1.\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40QT1YcJvOW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    # Switch model to training mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "    model.train()\n",
        "    \n",
        "    # We loop over the data iterator, and feed the inputs to the network and adjust the weights.\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if batch_idx > 20:\n",
        "          break\n",
        "        # Load the input features and labels from the training dataset\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # Reset the gradients to 0 for all learnable weight parameters\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass: Pass image data from training dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "        output = model(data)\n",
        "        \n",
        "        # Define our loss function, and compute the loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "        \n",
        "        # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update the neural network weights\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZgbzo6IgAZK",
        "colab_type": "text"
      },
      "source": [
        "## Define the Evaluation Step\n",
        "\n",
        "Here we add a line of code to:\n",
        "\n",
        "*   **wandb.log()** â€“ Log your metrics (accuracy, loss and epoch) and examples of images along with the predicted and true labels. This allows you to visualize your neural network's performance over time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUI5GslnvWKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader, classes):\n",
        "    # Switch model to evaluation mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    example_images = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            # Load the input features and labels from the test dataset\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            # Make predictions: Pass image data from test dataset, make predictions about class image belongs to (0-9 in this case)\n",
        "            output = model(data)\n",
        "            \n",
        "            # Compute the loss sum up batch loss\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            \n",
        "            # Get the index of the max log-probability\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            example_images.append(wandb.Image(data[0], caption = \"Pred: {} Truth: {}\".format(classes[pred[0].item()], classes[target[0]])))\n",
        "    \n",
        "    wandb.log({\n",
        "        \"Examples\": example_images,\n",
        "        \"Test Accuracy\": 100. * correct / len(test_loader.dataset),\n",
        "        \"Test Loss\": test_loss})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH8yXrpKhDip",
        "colab_type": "text"
      },
      "source": [
        "# Train, Edit, and Retrain\n",
        "Run wandb.init() each time you start a new run. For this tutorial we're logging results to an open, shared project called \"[pytorch-intro](https://app.wandb.ai/wandb/pytorch-intro/)\" so everyone's results go into the same project. (The entity refers to the team name this project is under. In this case I've set it up as my own team, \"wandb\").\n",
        "\n",
        "You can see other runs on the [project page](https://app.wandb.ai/wandb/pytorch-intro/).\n",
        "\n",
        "## Initialize Hyperparameters\n",
        "\n",
        "Here we add a few lines of code to:\n",
        "*   **wandb.init()** â€“ Initialize a new W&B run. Each run is single execution of the training script.\n",
        "*   **wandb.config** â€“ Save all your hyperparameters in a config object. This lets you use our app to sort and compare your runs by hyperparameter values.\n",
        "\n",
        "We encourage you to tweak these and run this cell again to see if you can achieve improved model performance!\n",
        "\n",
        "## Track Results\n",
        "*   **wandb.watch()** â€“ Fetch all layer dimensions, gradients, model parameters and log them automatically to your dashboard.\n",
        "*   **wandb.save()** â€“ Save the model checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsV8d2RbvteT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8c37dca9-56de-4a51-8957-28af3699c11a"
      },
      "source": [
        "wandb.init(entity=\"wandb\", project=\"pytorch-intro\")\n",
        "wandb.watch_called = True\n",
        "\n",
        "# Set up the configs\n",
        "config = wandb.config\n",
        "config.batch_size = 4\n",
        "config.test_batch_size = 10\n",
        "config.epochs = 50\n",
        "config.lr = 0.1\n",
        "config.momentum = 0.9\n",
        "config.no_cuda = True  # Disable CUDA Training\n",
        "config.seed = 42\n",
        "config.log_inteval = 10 # How many batches to wait before logging\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/wandb/pytorch-intro\" target=\"_blank\">https://app.wandb.ai/wandb/pytorch-intro</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/wandb/pytorch-intro/runs/a9og6jtl\" target=\"_blank\">https://app.wandb.ai/wandb/pytorch-intro/runs/a9og6jtl</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C-7TXhQ1lW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    # random.seed(config.seed)       # python random seed\n",
        "    torch.manual_seed(config.seed) # pytorch random seed\n",
        "    # numpy.random.seed(config.seed) # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(datasets.CIFAR10(root='./data', train=True, download=True, transform=transform, \n",
        "                                                                ), shuffle=True, batch_size=config.batch_size, **kwargs)\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(datasets.CIFAR10(root='./data', train=False,\n",
        "                                             download=True, transform=transform), batch_size=config.test_batch_size,\n",
        "                                             shuffle=False, **kwargs)\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat',\n",
        "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    \n",
        "    # Initialize our model, recursively go over all modules and convert their parameters and buffers to CUDA tensors (if device is set to cuda)\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum)\n",
        "\n",
        "    # WandB â€“ wandb.watch() automatically fetches all layer dimensions, gradients, model parameters and logs them automatically to your dashboard.\n",
        "    # Using log=\"all\" log histograms of parameter values in addition to gradients\n",
        "    wandb.watch(model, log=\"all\")\n",
        "\n",
        "    for epoch in range(1, config.epochs + 1):\n",
        "        train(config, model, device, train_loader, optimizer, epoch)\n",
        "        test(config, model, device, test_loader, classes)\n",
        "        \n",
        "    # WandB â€“ Save the model checkpoint. This automatically saves a file to the cloud and associates it with the current run.\n",
        "    torch.save(model.state_dict(), \"model.pt\")\n",
        "    wandb.save('model.pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRIpPKx-4oWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126,
          "referenced_widgets": [
            "a6809f5dfd2a4d59b42c508cab9590d4",
            "250290bee6a544ebbe555280bb56a0e1",
            "7270672815a6415bbb58fac758792ff8",
            "e8f720376e8b4812af9f8099d772e548",
            "4ba46186945c45cb83071e468648073a",
            "f0d0740ed5e1416f9949815c7590be33",
            "827727374e654121b0aa7403f97b369e",
            "d0b48b247a884fea9b9da1297a90293a"
          ]
        },
        "outputId": "be9c1c0e-81f5-4fbe-a3d6-5c0b1637ec5d"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6809f5dfd2a4d59b42c508cab9590d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlVItjlJ4pyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}