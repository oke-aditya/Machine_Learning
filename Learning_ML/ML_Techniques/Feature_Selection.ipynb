{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature-Selection.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu9NRPDKmv01",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBsFq3Z5mz3N",
        "colab_type": "text"
      },
      "source": [
        "* ` skelearn.feaeture_selection ` module can be used for feature selection / dimensionality reduction.\n",
        "\n",
        "* This helps to imporve the accuracy score or performance while dealing with large dimensional data.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_selection.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6MpkLvOnj_9",
        "colab_type": "text"
      },
      "source": [
        "## Removing features with low variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNcBXU-unsxz",
        "colab_type": "text"
      },
      "source": [
        "* Variance thresholding method can be used to remove features having low variance.\n",
        "\n",
        "* Set a particular variance threshold for a given attribute.\n",
        "\n",
        "* ` VarianceThreshold ` will remove the column having variance less than the given threshold.\n",
        "\n",
        "* By default ` VarianceThreshold ` removes the columns having zero variance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWNuS-lGk0Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQJdIbMIojJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "2eec4435-2f26-420f-e1c1-2372d8b63a15"
      },
      "source": [
        "X =  [[0,0,1], [0,1,0], [1,0,0], [0,1,1], [0,1,0], [0,1,1]]\n",
        "sel = VarianceThreshold(threshold = 0.16)\n",
        "sel.fit_transform(X)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 0],\n",
              "       [1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Ie4FJAplIw",
        "colab_type": "text"
      },
      "source": [
        "## Univariate Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bisX1agQppdL",
        "colab_type": "text"
      },
      "source": [
        "* Univariate Feature Selection works by considering statistical tests.\n",
        "\n",
        "* It is prepreocessing step before estimator\n",
        "\n",
        "* Use the ` SelectBest ` and apply ` fit_transform `\n",
        "\n",
        "* ` Select_best ` removes all the ` k ` highest scoring features\n",
        "\n",
        "* ` SelectPercentile ` removes all but a user-specified highest scoring percentage of feature.\n",
        "\n",
        "* Using common univariate statistical tests for each feature: false positive rate ` SelectFpr `, false discovery rate ` SelectFdr `, or famaily wise error ` SelectFwe `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8p8CGWjwDTI",
        "colab_type": "text"
      },
      "source": [
        "* Let us perform $ \\chi^2 $ test to the samples to retrieve only the two best features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmfnZAvYo7PH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSuHKrTwnQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18M4Q6_Swt-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a9229314-dfc7-4045-da2c-76c88a6c5982"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxl-MY49wvAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SB = SelectKBest(chi2, k=2)\n",
        "X_new = SB.fit_transform(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOE5f33w8fH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9e32bd7a-4c9d-4582-fb33-575ce114d221"
      },
      "source": [
        "print(X_new.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rSAJxD2xATo",
        "colab_type": "text"
      },
      "source": [
        "* These objects take input a scoring function and return univariate scores or p-values\n",
        "\n",
        "* Some guidelines: -\n",
        "\n",
        "* For regresiion: - `f_regrssion` , ` mutual_info_regression `\n",
        "* For classification: - ` chi2 ` , ` f_classif `, ` mutual_info_classif ` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlBAZeNuxlli",
        "colab_type": "text"
      },
      "source": [
        "* The methods based on F-test estimate the degree of linear dependency between two random varaibles.\n",
        "\n",
        "* Mututal information methods can capture any kind of statistical dependency, but they are non parametric and require more samples for accurate estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FoKu0FJx4qb",
        "colab_type": "text"
      },
      "source": [
        "## Recursive Feature Elimination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aokAINO8yvFi",
        "colab_type": "text"
      },
      "source": [
        "* Given an external estimator that assigns weights to features, recursive feature elimination is to select features by recursively considering smaller and smaller sets of features.\n",
        "\n",
        "* First, the estimator is trained on the inital set of features and the importance of the features is obtained using the ` coef_ ` method or through the ` feature_importances_ ` attribute.\n",
        "\n",
        "* Then, the least important features are pruned from current set of features.\n",
        "\n",
        "* This procedure is repeated on the pruned set unitil the desired number of features to be selected are eventually reached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqaY429o5CJM",
        "colab_type": "text"
      },
      "source": [
        "### E.g. Recursive feature elimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSrTADe3w9S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_friedman1\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AODZhob3YOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y = make_friedman1(n_samples = 50, n_features=10, random_state = 0)\n",
        "estimator = SVR(kernel = 'linear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtq2yYqi4MD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a71780b3-9fd8-4699-c3e5-39dc4534cbab"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXCDwwMP3kOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The classifier must support the coef_ or feature_importances_ attributes\n",
        "# Estimator denotes the estimator which we are using\n",
        "# n_feaures denotes the maximum number of features that we are want to choose\n",
        "# step denotes the amount of features to be removed at end of every iteration\n",
        "selector = RFE(estimator, n_features_to_select= 5, step=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8Qb2haS4Aev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selector = selector.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIa77my_4T0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c8f9190b-0731-448b-8944-aa74eed9d25c"
      },
      "source": [
        "# Use selector.support_ do display the mask of features, that is which features were selected\n",
        "print(selector.support_) "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True False False False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibxZg8nq4rJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5df9d123-d9c7-40c4-e3b5-0cdcb7f574f4"
      },
      "source": [
        "# Use selectior.ranking_ to correspond to the ranking of the ith position of the feature\n",
        "# Best features are ranked as 1\n",
        "print(selector.ranking_)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 6 4 3 2 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE4saI215FfW",
        "colab_type": "text"
      },
      "source": [
        "### E.g. Recursive feature elimination using cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHSbGbwN5OBI",
        "colab_type": "text"
      },
      "source": [
        "Feature ranking using cross-validation selection of best number of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMrJnbxi49J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_friedman1\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.svm import SVR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGsU_x0B51o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = make_friedman1(n_samples = 50, n_features = 10, random_state=0)\n",
        "estimator = SVR(kernel = 'linear')\n",
        "# cv denotes number of times we do cross_validation\n",
        "selector = RFECV(estimator, min_features_to_select=5, cv = 5)\n",
        "selector = selector.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRM67Bc-6RCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d9249093-8256-4056-e1dd-6480fe4e4f24"
      },
      "source": [
        "selector.support_"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True, False, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ_dBWFW6SBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "738680a8-e375-4b33-c41e-1a9e4ce92c51"
      },
      "source": [
        "selector.ranking_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfFOntdP6n16",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection using SelectFromModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "astITNbz7_jv",
        "colab_type": "text"
      },
      "source": [
        "* ` SelectFromModel ` is a meta-transformer that helps can be used with any estimator having ` coef_ ` or ` features_importance_ ` attribute after fitting.\n",
        "\n",
        "* The features are considered unimportant are removed, if the corresponding `coef_` or ` features_importance_ ` values are below the providied ` threshold `  parameter.\n",
        "\n",
        "* Apart from specifying the threshold numerically, there are built-in hueristics for finding for finding a threshold using a string argument such as \"mean\", \"mode\" or \"median\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Swsjcn-YPB",
        "colab_type": "text"
      },
      "source": [
        "### L1-based feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SID-RqBu-dj_",
        "colab_type": "text"
      },
      "source": [
        "* Linear models penalized with L1 norm have sparse solutions.\n",
        "* When the goal is to reduce the dimensionality of the data to use with another classifier then they can be used along with the ` feature_selection.SelectFromModel ` to select the non-zero coefficients.\n",
        "* In particular, sparse estimators useful for this purpose are the 1 `  linear_model.Lasso ` for regression, and of ` linear_model.LogisticRegression `and ` svm.LinearSVC ` for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4gyWXIJ6UC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdNqxA6A_Jc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LCJq-XB_P3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y = iris.data, iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7MInQ9P_Rq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b7d3eecb-6652-411e-90fb-f0fa6440a03b"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMXp0jLU_TQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lsvc = LinearSVC(C = 0.01, penalty = \"l1\", dual = False, max_iter = 2500)\n",
        "lsvc = lsvc.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEjxJ1wyAdLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Estimator contains the name of estimator we are trying to fit\n",
        "# Whether a prefit model is expected to be passed into the constructor directly or not.\n",
        "# If True, transform must be called directly and SelectFromModel cannot be used with cross_val_score, \n",
        "# GridSearchCV and similar utilities that clone the estimator. \n",
        "# Otherwise train the model using fit and then transform to do feature selection.\n",
        "model = SelectFromModel(lsvc, prefit = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kf1BowRBOW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3cf1b05e-0656-4ff5-a47b-a86ab52a25ed"
      },
      "source": [
        "X_new = model.transform(X)\n",
        "print(X_new.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T0DHA7oBiHj",
        "colab_type": "text"
      },
      "source": [
        "* With SVMs and logistic-regression, the parameter C controls the sparsity: the smaller C the fewer features selected. \n",
        "\n",
        "* With Lasso, the higher the alpha parameter, the fewer features selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36b_t6RNBqC2",
        "colab_type": "text"
      },
      "source": [
        "### Tree-based feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCw9LqKgClpz",
        "colab_type": "text"
      },
      "source": [
        "* Tree-based estimator can be used to compute the feature importances which in turn can be used to dicared the irrelevant features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDO8JaGlBTIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3Fi5wSlEVSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u4mLhrQEWuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = iris.data, iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X470fD3OEYd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e230a9e7-8b65-44b4-a35b-71e118e64697"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNZfgw3uEaim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=100, n_jobs = -1, random_state=0)\n",
        "clf = clf.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYB0YHGDEm1X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bac8f1fe-6366-4d3e-e84b-a9a66449217e"
      },
      "source": [
        "clf.feature_importances_"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09090795, 0.02453104, 0.46044474, 0.42411627])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DnLLbI9Iop0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SelectFromModel(clf, threshold = 0.3, prefit = True)\n",
        "X_new = model.transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG5ZLspCI0za",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "728b2c1f-8e4b-499b-b8dd-fc1a5d0cbc2d"
      },
      "source": [
        "print(X_new.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6UoINMxJf38",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection as Part of ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-PvgxX_J1Vz",
        "colab_type": "text"
      },
      "source": [
        "* Feature selection is usually used as a prepreocessing step before doing actual learning.\n",
        "\n",
        "* Recommended way to do this is use ` sklearn.pipeline.Pipeline `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igNoMUPwKXq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-lIwjZRI8XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('feature_selection', SelectFromModel(LinearSVC(max_iter = 8000))),\n",
        "    ('classification', RandomForestClassifier(n_estimators = 100))   \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op8zzqgaKUqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = clf.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op-wn6shK6gh",
        "colab_type": "text"
      },
      "source": [
        "* In this snippet we make use of `sklearn.svm.LinearSVC` with ` SelectfromModel `.\n",
        "* ` SelectfromModel ` selects the important feature and passes it to  `RandomForestClassifier`.\n",
        "* `RandomForestClassifer` trains only on the relevant input given by the pipeline"
      ]
    }
  ]
}