{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_1_intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1.12.0\n"
        }
      ],
      "source": [
        "print(tf.__version__)   # Tutorial written on V1.15.0 ensure that you are using the same or anything compatible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jtKIAUx_NhIu"
      },
      "source": [
        "# Creating A Dataflow Graph Using Tensorflow Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "In these few lines, there are a lot of peculiarities of TensorFlow and its way of building a computational graph. \n",
        "- This graph represents the matrix product between the constant tensor identified by the A Python variable and the constant tensor identified by the x Python variable and the sum of the resulting matrix with the tensor identified by the b Python variable. \n",
        "\n",
        "- The result of the computation is represented by the y Python variable, also known as the output of the tf.add node named result in the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "A = tf.constant([[1,2], [3,4]], dtype=tf.float32)\n",
        "X = tf.constant([[0,10], [2.5,4]], dtype=tf.float32)\n",
        "b = tf.constant([[2,3], [3,4.5]], dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = tf.add(tf.matmul(A,X), b,name=\"result\")             # Y = AX+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Tensor(\"result:0\", shape=(2, 2), dtype=float32)\n"
        }
      ],
      "source": [
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- Please note the separation between the concept of a Python variable and a node in the graph: we're using Python only to describe the graph; the name of the Python variable means nothing in the graph definition.\n",
        "\n",
        "- Please note that we are just describing the graph—the calls to the TensorFlow API are just adding operations (nodes) and connections (edges) among them; there is no computation performed in this phase. \n",
        "\n",
        "- In TensorFlow 1.x, the following approach needs to be followed—static graph definition and execution, while this is no longer mandatory in 2.0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer = tf.summary.FileWriter(\"log/matmul\", tf.get_default_graph())\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "To run the tensorboard\n",
        "- tensorboard --logdir Learning_Tensorflow\\log\\matmul"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining Tensorflow Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- The following code snippet shows how our baseline example can be wrapped into a separate graph\n",
        "- How a second independent graph can be created in the same Python script,\n",
        "- how we can change the node names, adding a prefix, using tf.name_scope. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "g1 = tf.Graph()\n",
        "g2 = tf.Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "with g1.as_default():\n",
        "    A = tf.constant([[1,2], [3,4]], dtype=tf.float32)\n",
        "    X = tf.constant([[2,4], [3.5,3.5]], dtype=tf.float32)\n",
        "    b = tf.constant([[1,-1]], dtype=tf.float32)\n",
        "    y = tf.add(tf.matmul(A,X), b, name=\"result\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Tensor(\"scope_a/x:0\", shape=(), dtype=int32)\nTensor(\"scope_b/x:0\", shape=(), dtype=int32)\n"
        }
      ],
      "source": [
        "with g2.as_default():\n",
        "    with tf.name_scope(\"scope_a\"):\n",
        "        x = tf.constant(1, name=\"x\")\n",
        "        print(x)\n",
        "    with tf.name_scope(\"scope_b\"):\n",
        "        x = tf.constant(2, name=\"x\")\n",
        "        print(x)\n",
        "    y = tf.constant(12)\n",
        "    z = x * y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- Then, we define two summary writers. We need to use two different tf.summary.FileWriter objects to log two separate graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer = tf.summary.FileWriter(\"log/two_graphs/g1\", g1)\n",
        "writer = tf.summary.FileWriter(\"log/two_graphs/g2\",g2)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- Nodes with the same name, x in the example, can live together in the same graph, but they have to be under different scopes. \n",
        "- In fact, being under different scopes makes the nodes completely independent and completely different objects."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "In general, every tensor has a name, a type, a rank, and a shape:\n",
        "\n",
        "- The name uniquely identifies the tensor in the computational graphs. Using tf.name_scope, we can prefix tensor names, thus changing their full path. \n",
        "\n",
        "- The type is the data type of the tensor; for example, tf.float32, tf.int8, and so on.\n",
        "\n",
        "- The rank is the number of dimensions of a tensor.\n",
        "\n",
        "- The shape is the number of elements in each dimension; for example, a scalar has rank 0 and an empty shape of (), a vector has rank 1 and a shape of (D0), a matrix has rank 2 and a shape of (D0, D1), and so on. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- Being a C++ library, TensorFlow is strictly statically typed. \n",
        "- This means that the type of every operation/tensor must be known at graph definition time. Moreover, this also means that it is not possible to execute an operation among incompatible types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using operator overloading we can also write\n",
        "A = tf.constant([[1,2], [3,4]], dtype=tf.float32)\n",
        "X = tf.constant([[2,4], [3.5,3.5]], dtype=tf.float32)\n",
        "b = tf.constant([[1,-1]], dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = A@X + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Tensor(\"result:0\", shape=(2, 2), dtype=float32)\n"
        }
      ],
      "source": [
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tf.device"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- tf.device creates a context manager that matches a device. The function allows the user to request that all operations created within the context it creates are placed on the same device.\n",
        "\n",
        "- The devices identified by tf.device are more than physical devices; in fact, it is capable of identifying devices such as remote servers, remote devices, remote workers, and different types of physical devices (GPUs, CPUs, and TPUs). \n",
        "\n",
        "- It is required to follow a device specification to correctly instruct the framework to use the desired device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.device(\"/CPU:0\"):\n",
        "    A = tf.constant([[1,2], [3,4]], dtype=tf.float32)\n",
        "    B = tf.constant([[2,3], [-1,-2]], dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IF we have a GPU\n",
        "with tf.device(\"/GPU:0\"):\n",
        "    mul = A @ B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer = tf.summary.FileWriter(\"log/matmul_optimized\", tf.get_default_graph())\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- When using the static-graph and session execution parading, the execution is completely separated from the graph definition. This is no longer true in eager execution, "
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tf.session"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- tf.Session is a class that TensorFlow provides to represent a connection between the Python program and the C++ runtime. "
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- The tf.Session object is the only object able to communicate directly with the hardware (through the C++ runtime), placing operations on the specified devices, using the local and distributed TensorFlow runtime, with the goal of concretely building the defined graph.\n",
        " - The tf.Session object is highly optimized and, once correctly built, caches tf.Graph in order to speed up its execution."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.sessison object does these three functions\n",
        "\n",
        "- Acquires resources.\n",
        "- Use resources.\n",
        "- Release resources. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The context manager opens the session\n",
        "with tf.Session() as sess:\n",
        "    # Use the session to execute operations\n",
        "    sess.run(...)\n",
        "# Out of the context, the session is closed and the resources released"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the IP and port of the TensorFlow server\n",
        "ip = \"192.168.1.90\"\n",
        "port = 9877\n",
        "with tf.Session(f\"grpc://{ip}:{port}\") as sess:\n",
        "    sess.run(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "By default, the tf.Session will capture and use the default tf.Graph object. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with tf.device(\"/CPU:0\"):\n",
        "A = A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "x = tf.constant([[0, 10], [0, 0.5]])\n",
        "b = tf.constant([[1, -1]], dtype=tf.float32)\n",
        "y = tf.add(tf.matmul(A, x), b, name=\"result\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer = tf.summary.FileWriter(\"log/matmul\",tf.get_default_graph())\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.Session() as sess:\n",
        "    A_value, x_value, b_value =sess.run([A,x,b])\n",
        "    y_value = sess.run(y)\n",
        "\n",
        "    # Overwrite\n",
        "    y_new = sess.run(y, feed_dict={b:np.zeros((1,2))})\n",
        "\n",
        "print(f\"A: {A_value}\\nx: {x_value}\\nb: {b_value}\\n\\ny: {y_value}\")\n",
        "print(f\"y_new: {y_new}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- The first sess.run call evaluates the three tf.Tensor objects, A, x, b, and returns their values as numpy arrays.\n",
        "- The third sess.run call shows how it is possible to inject into the computational graph values from the outside, as numpy arrays, overwriting a node. The feed_dict parameter allows you to do this: usually, inputs are passed to the graph using the feed_dict parameter and through the overwriting of the tf.placeholder operation created exactly for this purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- tf.placeholder is just a placeholder created with the aim of throwing an error when values from the outside are not injected inside the graph. However, the feed_dict parameter is more than just a way to feed the placeholders. In fact, the preceding example shows how it can be used to overwrite any node."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variables in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- A variable is an object that maintains a state in the graph across multiple calls to sess.run. A variable is added to tf.Graph by constructing an instance of the tf.Variable class.\n",
        "\n",
        "- A variable is completely defined by the pair (type, shape), and variables created by calling tf.Variable can be used as input for other nodes in the graph; in fact, the tf.Tensor and tf.Variable objects can be used in the same manner when building a graph.\n",
        "\n",
        "- Variables have more attributes with respect to tensors: a variable object must be initialized and thus have its initializer; a variable is, by default, added to the global variables and trainable variable graph collections. If a variable is set as non-trainable, it can be used by the graph to store the state, but the optimizers will ignore it when performing the learning process."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## tf.variable"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- Creating a variable by calling tf.Variable will always create a new variable and it always requires an initial value to be specified. \n",
        "- Truncated Normal gives values in normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "size_in = 28\n",
        "size_out = 28\n",
        "w = tf.Variable(tf.truncated_normal([5,5,size_in,size_out], stddev=0.1), name = 'W')\n",
        "b = tf.Variable(tf.constant(0.1, shape = [size_out]), name = \"B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<tf.Variable 'W:0' shape=(5, 5, 28, 28) dtype=float32_ref>\n<tf.Variable 'B:0' shape=(28,) dtype=float32_ref>\n"
        }
      ],
      "source": [
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Since each call to tf.Variable creates a new variable in the graph, it is the perfect candidate for the creation of layers"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "This creates a 5x5 Convolution Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Conv2D(input, size_in, size_out, name = \"conv\"):\n",
        "    '''\n",
        "    Creates a conv2D layer which we use frequrently.\n",
        "    Input: a 4D tensor (batch_size, dim1, dim2, channels)\n",
        "    size_in: Can be inferred from input.\n",
        "    size_out: No. of kernels to learn.\n",
        "    Ouput: Return of Conv2D operation applied + MaxPooling which halves the dimesnsion\n",
        "    '''\n",
        "\n",
        "    with tf.name_scope(name):\n",
        "        w = tf.variable(tf.truncated_normal([5,5,size_in,size_out], stddev=0.1), name='W')\n",
        "        b = tf.variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
        "        conv = tf.nn.Conv2D(input, w, strides = [1,1,1,1], padding='SAME')\n",
        "        act = tf.nn.relu(conv + b)\n",
        "        tf.summary.histogram(\"w\",w)\n",
        "        tf.summary.historgram(\"b\",b)\n",
        "        return(tf.nn.max_pool(act, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Defining a fully_connected layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fc(input, size_in, size_out, name=\"fc\"):\n",
        "    '''\n",
        "    Args: Input 2D tensor\n",
        "    size_in: it could be inferred by the input (input.shape[-1])\n",
        "    size_out: the number of output neurons kernel to learn\n",
        "    Output: Linear 1D output\n",
        "    '''\n",
        "\n",
        "    with tf.name_scope(name):\n",
        "        w = tf.Variable(tf.truncated_normal([size_in,size_out], stddev=0.1), name=\"W\")\n",
        "        b = tf.Variable(tf.constant(0.1, shape = [size_out]), name=\"B\")\n",
        "        act = tf.matmul(input, w) + b\n",
        "        tf.summary.histogram(\"w\",w)\n",
        "        tf.summary.histogram(\"b\",b)\n",
        "        return(act)\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Both functions also use the tf.summary module to log the histograms of the weight, bias, and activation values, which can change during training.\n",
        "\n",
        "The call to a tf.summary method automatically adds the summaries to a global collection that is used by tf.Saver and tf.SummaryWriter objects to log every summary value in the TensorBoard log directory"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "## tf.Get_variable"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- To enable variable sharing where we need to use the same variable name for different layers.\n",
        "- tf.get_variable is always used together with tf.variable_scope since it enables the variable sharing capabilities of tf.get_variable through its reuse parameter\n",
        "- Hence, a layer that uses tf.get_variable to define variables can be used in conjunction with tf.variable_scope to define or reuse the layer's variables. \n",
        "- This is useful in GANs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.variable_scope(\"scope\", reuse=True):\n",
        "    a = tf.get_variable(\"v\", [1])\n",
        "with tf.variable_scope(\"scope\", reuse=True):\n",
        "    b = tf.get_variable(\"v\",[1])\n",
        "with tf.variable_scope(\"scope\", reuse=True):\n",
        "    c = tf.get_variable(\"v\",[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Conv2D(input, size_in, size_out):\n",
        "    w = tf.get_variable('W', [5,5,size_in,size_out], initializer = tf.truncated_normal_initializer(stddev=0.1))\n",
        "    b = tf.get_variable('B', [size_out], initializer=tf.constant_initializer(0.1))\n",
        "    conv = tf.nn.conv2d(input, w, strides = [1,1,1,1], padding = 'SAME')\n",
        "    act = tf.nn.relu(conv+b)\n",
        "    tf.summary.histogram(\"w\",w)\n",
        "    tf.summary.histogram(\"b\",b)\n",
        "    return(tf.nn.max_pool(act, ksize = [1,2,2,1], strides=[1,2,2,1], padding='SAME'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fc(input, size_in, size_out):\n",
        "    w = tf.get_variable('W', [size_in,size_out], initializer = tf.truncated_normal_initializer(sttddev=0.1))\n",
        "    b = tf.get_variable('B', [size_out], initializer=tf.constant_initializer(0.1))\n",
        "    act = tf.matmul(input, w) + b\n",
        "    tf.summary.histogram(\"w\",W)\n",
        "    tf.summary.histogram(\"b\",b)\n",
        "    return(act)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "input = tf.placeholder(tf.float32, (None, 28,28,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.variable_scope(\"first\",reuse=True):\n",
        "    conv1 = Conv2D(input, input.shape[-1].value, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "with tf.variable_scope(\"second\",reuse=tf.AUTO_REUSE):\n",
        "    conv2 = Conv2D(conv1, conv1.shape[-1].value, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- TensorFlow already comes with a module named tf.layers, which contains all the most common and widely used layers, defined using tf.get_variable under the hood, and therefore, layers can be used in conjunction with tf.variable_scope to share their variables."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tf.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "**Disclaimer**\n",
        "- tf.layers is completely removed in tensorflow 2.0\n",
        "- We need to use tf.keras.layers instead.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "The tf.layers module in TensorFlow 1.x and the tf.keras.layers module in TensorFlow 2.0 provide an excellent API to define machine learning models in a convenient and powerful way. \n",
        "\n",
        "Every layer in tf.layers, defines variables using tf.get_variable, and therefore, each layer defined in this way can use the variable-sharing features provided by tf.variable_scope."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Creating LeNet using tf.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def le_cnn(x, n_classes, reuse, is_training):\n",
        "    \"\"\"Defines a convolutional neural network for classification.\n",
        "    Input: x: 4D Tensor (Batch_size, dim1, dim2, channels)\n",
        "    n_classes: the number of classes, hence, the number of output neurons.\n",
        "    reuse: the tf.variable_scope reuse parameter\n",
        "    is_training: boolean variable indicates if we are training\n",
        "\n",
        "    return: An output layer\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # no. of filters = 64\n",
        "    # size of kernel = 3x3\n",
        "    conv1 = tf.layers.conv2d(x, 64, 3, activation=tf.nn.relu)\n",
        "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
        "\n",
        "    conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
        "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
        "\n",
        "    # Flattening into 2D to connect with fc\n",
        "\n",
        "    shape = (-1, conv2.shape[1].value * conv2.shape[2].value * conv2.shape[3].value)\n",
        "    fc1 = tf.reshape(conv2, shape)\n",
        "\n",
        "    # Fully connected layer\n",
        "    fc1 = tf.layers.dense(fc1, 1024)\n",
        "    out = tf.layers.dense(fc1, n_classes)\n",
        "    return(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = tf.placeholder(tf.float32, (None,28,28,1))\n",
        "logits = le_cnn(input, 10, reuse=False, is_training = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Automatic Differentiation and Training Network"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- tf contains automatic differentiation.\n",
        "- All the losses are in tf.losses\n",
        "- Optimizers can be found in tf.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = tf.placeholder(tf.int32, (None,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss function\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
        "# Optimizer\n",
        "opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# logging the graph\n",
        "writer = tf.summary.FileWriter(\"log/graph_loss\", tf.get_default_graph())\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- Python is used only to build a graph and to do non-learning related operations"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A working Example Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To scale in [-1,1] range\n",
        "train_x = (train_x / 255.) * 2 - 1\n",
        "test_X = (test_x / 255.) * 2 - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adding 1 last dimenstion to make it in (28,28,1)\n",
        "train_x = np.expand_dims(train_x,-1)\n",
        "test_x = np.expand_dims(test_x,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "number_batches_train = int(train_x.shape[0] / batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Batch size is 32\nNumber of batches per epochs = 1875\n"
        }
      ],
      "source": [
        "print(\"Batch size is %d\" %(batch_size))\n",
        "print(\"Number of batches per epochs = %d\" %(number_batches_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Defining Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predictions = tf.argmax(logits, 1)\n",
        "# # correct predictions: [BATCH_SIZE] tensor\n",
        "# correct_predictions = tf.equal(labels, predictions)\n",
        "# accuracy = tf.redeuce_mean(tf.cast(correct_predictions, tf.float32), name = \"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
        "# loss_summary = tf.summary.scalar(\"loss\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer = tf.summary.FileWriter(\"log/graph_loss\", tf.get_default_graph())\n",
        "validation_summary_writer = tf.summary.FileWriter(\"log/graph_loss/validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Example"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "- tf.Saver is the object the TensorFlow Python API provides to save the current model variables. Please note that the tf.Saver object saves the variables only and not the graph structure!\n",
        "- To save both the graph structure and variables, a SavedModel object is required;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train():\n",
        "    # tf.device(\"CPU:0\")\n",
        "    input = tf.placeholder(tf.float32, (None, 28, 28, 1))\n",
        "    labels = tf.placeholder(tf.int64, (None,))\n",
        "    logits = le_cnn(input, 10, reuse=False, is_training=True)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
        "    global_step = tf.train.get_or_create_global_step()\n",
        "    train_op = tf.train.AdamOptimizer().minimize(loss, global_step)\n",
        "\n",
        "    writer = tf.summary.FileWriter(\"log/graph_loss\", tf.get_default_graph())\n",
        "    validation_summary_writer = tf.summary.FileWriter(\n",
        "        \"log/graph_loss/validation\")\n",
        "\n",
        "    init_op = tf.global_variables_initializer()\n",
        "\n",
        "    predictions = tf.argmax(logits, 1)\n",
        "    # correct predictions: [BATCH_SIZE] tensor\n",
        "    # tf.metrics.accuracy(predictions, train_y)\n",
        "    \n",
        "    correct_predictions = tf.equal(labels, predictions)\n",
        "    accuracy = tf.reduce_mean(\n",
        "        tf.cast(correct_predictions, tf.float32), name=\"accuracy\")\n",
        "\n",
        "    accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
        "    loss_summary = tf.summary.scalar(\"loss\", loss)\n",
        "    # Input preprocessing a Python stuff\n",
        "    (train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n",
        "    # Scale input in [-1, 1] range\n",
        "    train_x = train_x / 255. * 2 - 1\n",
        "    train_x = np.expand_dims(train_x, -1)\n",
        "    test_x = test_x / 255. * 2 - 1\n",
        "    test_x = np.expand_dims(test_x, -1)\n",
        "\n",
        "    epochs = 10\n",
        "    batch_size = 32\n",
        "    nr_batches_train = int(train_x.shape[0] / batch_size)\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Number of batches per epoch: {nr_batches_train}\")\n",
        "\n",
        "    validation_accuracy = 0\n",
        "    saver = tf.train.Saver()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init_op)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for t in range(nr_batches_train):\n",
        "                start_from = t * batch_size\n",
        "                to = (t + 1) * batch_size\n",
        "\n",
        "                loss_value, _, step = sess.run(\n",
        "                    [loss, train_op, global_step],\n",
        "                    feed_dict={\n",
        "                        input: train_x[start_from:to],\n",
        "                        labels: train_y[start_from:to]\n",
        "                    })\n",
        "                if t % 10 == 0:\n",
        "                    print(f\"{step}: {loss_value}\")\n",
        "            print(\n",
        "                f\"Epoch {epoch} terminated: measuring metrics and logging summaries\"\n",
        "            )\n",
        "\n",
        "            saver.save(sess, \"log/graph_loss/model\")\n",
        "            start_from = 0\n",
        "            to = 128\n",
        "            train_accuracy_summary, train_loss_summary = sess.run(\n",
        "                [accuracy_summary, loss_summary],\n",
        "                feed_dict={\n",
        "                    input: train_x[start_from:to],\n",
        "                    labels: train_y[start_from:to]\n",
        "                })\n",
        "\n",
        "            validation_accuracy_summary, validation_accuracy_value, validation_loss_summary = sess.run(\n",
        "                [accuracy_summary, accuracy, loss_summary],\n",
        "                feed_dict={\n",
        "                    input: test_x[start_from:to],\n",
        "                    labels: test_y[start_from:to]\n",
        "                })\n",
        "\n",
        "            # save values in TensorBoard\n",
        "            writer.add_summary(train_accuracy_summary, step)\n",
        "            writer.add_summary(train_loss_summary, step)\n",
        "\n",
        "            validation_summary_writer.add_summary(validation_accuracy_summary,\n",
        "                                                  step)\n",
        "            validation_summary_writer.add_summary(validation_loss_summary, step)\n",
        "\n",
        "            validation_summary_writer.flush()\n",
        "            writer.flush()\n",
        "\n",
        "            # model selection\n",
        "            if validation_accuracy_value > validation_accuracy:\n",
        "                validation_accuracy = validation_accuracy_value\n",
        "                saver.save(sess, \"log/graph_loss/best_model/best\")\n",
        "\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Batch size: 32\nNumber of batches per epoch: 1875\n"
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Cannot assign a device for operation matmul_2: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node matmul_2 (defined at <ipython-input-18-41fef96e24eb>:3)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](Const_6, Const_7)]]\n\nCaused by op 'matmul_2', defined at:\n  File \"C:\\Program Files\\Python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files\\Python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Program Files\\Python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Program Files\\Python36\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Program Files\\Python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-41fef96e24eb>\", line 3, in <module>\n    mul = A @ B\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 866, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2057, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4856, in mat_mul\n    name=name)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation matmul_2: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node matmul_2 (defined at <ipython-input-18-41fef96e24eb>:3)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](Const_6, Const_7)]]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
            "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation matmul_2: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[{{node matmul_2}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](Const_6, Const_7)]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-96-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-95-c98d24f94b2b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation matmul_2: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node matmul_2 (defined at <ipython-input-18-41fef96e24eb>:3)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](Const_6, Const_7)]]\n\nCaused by op 'matmul_2', defined at:\n  File \"C:\\Program Files\\Python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files\\Python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Program Files\\Python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Program Files\\Python36\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Program Files\\Python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-41fef96e24eb>\", line 3, in <module>\n    mul = A @ B\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 866, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2057, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4856, in mat_mul\n    name=name)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation matmul_2: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node matmul_2 (defined at <ipython-input-18-41fef96e24eb>:3)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](Const_6, Const_7)]]\n"
          ]
        }
      ],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}