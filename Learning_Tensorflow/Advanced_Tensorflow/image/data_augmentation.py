# -*- coding: utf-8 -*-
"""data_augmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RQYepOnJuD75a1lgM17s2xZNIxtEIFmC

# Data Augmentation in Tensorflow

- This tutorial demonstrates manual image manipulations and augmentation using tf.image.
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

import tensorflow_datasets as tfds

from tensorflow.keras.datasets import mnist
from tensorflow.keras import layers
import PIL

"""# Some examples of using tf.image"""

image_path = tf.keras.utils.get_file("cat.jpg", "https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg")
PIL.Image.open(image_path)

# Reading image in tensor format
image_string = tf.io.read_file(image_path)
image = tf.image.decode_jpeg(image_string, channels=3)

# Function to vizualize and compare the two images
def visualize(original, augmented):
  fig = plt.figure()
  plt.subplot(1,2,1)
  plt.title('Original image')
  plt.xticks([])
  plt.yticks([])
  plt.imshow(original)

  plt.subplot(1,2,2)
  plt.title('Augmented image')
  plt.xticks([])
  plt.yticks([])
  plt.imshow(augmented)

flipped = tf.image.flip_left_right(image)
visualize(image, flipped)

grayscaled = tf.image.rgb_to_grayscale(image)
visualize(image, tf.squeeze(grayscaled))

saturated = tf.image.adjust_saturation(image, saturation_factor=3)
visualize(image, saturated)

bright = tf.image.adjust_brightness(image, delta=0.3)
visualize(image, bright)

rotated = tf.image.rot90(image)
visualize(image, rotated)

cropped = tf.image.central_crop(image, central_fraction=0.6)
visualize(image, cropped)

"""# Using the augemented images to train a DL model"""

dataset, info = tfds.load('mnist', as_supervised=True, with_info=True)
train_dataset, test_dataset = dataset['train'], dataset['test']

num_train_examples = info.splits['train'].num_examples

print(num_train_examples)

"""Write a function to augment the images. Map it over the the dataset. This returns a dataset that augments the data on the fly."""

def convert(image, label):
    # this will typecast and normalize the image
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    return image, label

def augment(image, label):
    image, label = convert(image, label)
    # image = tf.image.convert_image_dtype()
    image = tf.image.resize_with_crop_or_pad(image, 34, 34)  #  Adds a padding of 6 pixels
    image = tf.image.random_crop(image, size=(28, 28, 1))    # converts back to 28x28
    image = tf.image.random_brightness(image, max_delta=0.5)

    return image, label

BATCH_SIZE = 64
NUM_EXAMPLES = 60000

augmented_train_batches = (
    train_dataset.take(NUM_EXAMPLES).cache().shuffle(NUM_EXAMPLES // 4).map(augment).batch(BATCH_SIZE).prefetch(1)
)

print(augmented_train_batches)

validation_batches = (
    test_dataset
    .map(convert)
    .batch(2*BATCH_SIZE)
)

def make_model():
    model = tf.keras.Sequential([
                                 layers.Conv2D(32, (3,3), padding='same', input_shape=(28, 28, 1), activation='relu'),
                                 layers.Conv2D(64, (3,3), padding='same', activation='relu'),
                                 layers.Conv2D(128, (3,3), padding='same', activation='relu'),
                                 layers.Flatten(),
                                 layers.Dense(128, activation='relu'),
                                 layers.Dense(128, activation='relu'),
                                 layers.Dense(10, activation='softmax')
    ])

    return model

model = make_model()

model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['acc'])

hist = model.fit(augmented_train_batches, validation_data=validation_batches, epochs=10)

