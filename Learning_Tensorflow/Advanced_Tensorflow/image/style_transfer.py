# -*- coding: utf-8 -*-
"""Style_Transfer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fb-6xfYInQSNdIDvnYYK1jWHNpAAYH22

# Neural Style Transfer

Neural style transfer is an optimization technique used to take two images—a content image and a style reference image (such as an artwork by a famous painter)—and blend them together so the output image looks like the content image, but “painted” in the style of the style reference image.

This is implemented by optimizing the output image to match the content statistics of the content image and the style statistics of the style reference image. These statistics are extracted from the images using a convolutional network.

# Preprocessing
"""

import tensorflow as tf

import IPython.display as display

import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.rcParams['figure.figsize'] = (12,12)
mpl.rcParams['axes.grid'] = False

import numpy as np
import PIL.Image
import time
import functools

def tensor_to_image(tensor):
    tensor = tensor * 255
    tensor = np.array(tensor, dtype=np.uint8)

    if(np.ndim(tensor) > 3):
        assert tensor.shape[0] == 1
        tensor = tensor[0]
    
    return PIL.Image.fromarray(tensor)

"""Download images and choose a style image and a content image:"""

content_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')
# https://commons.wikimedia.org/wiki/File:Vassily_Kandinsky,_1913_-_Composition_7.jpg
style_path = tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')

"""Visualize the input

Define a function to load an image and limit its maximum dimension to 512 pixels.
"""

def load_img(path_to_img):
  max_dim = 512
  img = tf.io.read_file(path_to_img)
  img = tf.image.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32)

  shape = tf.cast(tf.shape(img)[:-1], tf.float32)
  long_dim = max(shape)
  scale = max_dim / long_dim

  new_shape = tf.cast(shape * scale, tf.int32)

  img = tf.image.resize(img, new_shape)
  img = img[tf.newaxis, :]
  return img

def imshow(image, title=None):
  if len(image.shape) > 3:
    image = tf.squeeze(image, axis=0)

  plt.imshow(image)
  if title:
    plt.title(title)

content_image = load_img(content_path)
style_image = load_img(style_path)

plt.subplot(1, 2, 1)
imshow(content_image, 'Content Image')

plt.subplot(1, 2, 2)
imshow(style_image, 'Style Image')

print(content_image.shape)
print(style_image.shape)

"""# Fast Style Transfer using TF-Hub

This tutorial demonstrates the original style-transfer algorithm. Which optimizes the image content to a particular style. Before getting into the details let's see how the TensorFlow Hub module does
"""

import tensorflow_hub as hub

hub_module = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/1')
stylized_images = hub_module(tf.constant(content_image), tf.constant(style_image))[0]
print(stylized_images.shape)

tensor_to_image(stylized_images)

"""# Define content and style representations

- Use the intermediate layers of the model to get the content and style representations of the image.

- Starting from the network's input layer, the first few layer activations represent low-level features like edges and textures. 

- As you step through the network, the final few layers represent higher-level features—object parts like wheels or eyes.

- In this case, you are using the VGG19 network architecture, a pretrained image classification network. 

- These intermediate layers are necessary to define the representation of content and style from the images. 

- For an input image, try to match the corresponding style and content target representations at these intermediate layers.
"""

x = tf.keras.applications.vgg19.preprocess_input(content_image * 255)
x = tf.image.resize(x, (224, 224))

vgg = tf.keras.applications.VGG19(include_top=True, weights='imagenet')

prediction_probabilities = vgg(x)
prediction_probabilities.shape

predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(prediction_probabilities.numpy())[0]
[(class_name, prob) for (number, class_name, prob) in predicted_top_5]

"""Now load a VGG19 without the classification head, and list the layer names"""

vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')

print()
for layer in vgg.layers:
  print(layer.name)

"""Choose intermediate layers from the network to represent the style and content of the image:"""

# Content layer where will pull our feature maps
content_layers = ['block5_conv2'] 

# Style layer of interest
style_layers = ['block1_conv1',
                'block2_conv1',
                'block3_conv1', 
                'block4_conv1', 
                'block5_conv1']

num_content_layers = len(content_layers)
num_style_layers = len(style_layers)

"""# Intermediate layers for style and content

So why do these intermediate outputs within our pretrained image classification network allow us to define style and content representations?

At a high level, in order for a network to perform image classification (which this network has been trained to do), it must understand the image.

 This requires taking the raw image as input pixels and building an internal representation that converts the raw image pixels into a complex understanding of the features present within the image.

This is also a reason why convolutional neural networks are able to generalize well: they’re able to capture the invariances and defining features within classes (e.g. cats vs. dogs) that are agnostic to background noise and other nuisances. 

Thus, somewhere between where the raw image is fed into the model and the output classification label, the model serves as a complex feature extractor. By accessing intermediate layers of the model, you're able to describe the content and style of input images.

# Build the model

The networks in tf.keras.applications are designed so you can easily extract the intermediate layer values using the Keras functional API.

To define a model using the functional API, specify the inputs and outputs:

model = Model(inputs, outputs)

This following function builds a VGG19 model that returns a list of intermediate layer outputs:
"""

def vgg_layers(layer_names):
    '''  Creates a vgg model that returns a list of intermediate output values.'''
    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')
    vgg.trainable = False

    outputs = [vgg.get_layer(name).output for name in layer_names]

    model = tf.keras.Model([vgg.input], outputs)

    return model

style_extractor = vgg_layers(style_layers)
style_outputs = style_extractor(style_image*255)

#Look at the statistics of each layer's output
for name, output in zip(style_layers, style_outputs):
  print(name)
  print("  shape: ", output.numpy().shape)
  print("  min: ", output.numpy().min())
  print("  max: ", output.numpy().max())
  print("  mean: ", output.numpy().mean())
  print()

"""# Calculate style

The content of an image is represented by the values of the intermediate feature maps.

It turns out, the style of an image can be described by the means and correlations across the different feature maps. Calculate a Gram matrix that includes this information by taking the outer product of the feature vector with itself at each location, and averaging that outer product over all locations. This Gram matrix can be calcualted for a particular layer as:

![image.png](data:image/png;base64,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)
"""

def gram_matrix(input_tensor):
    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)
    input_shape = tf.shape(input_tensor)
    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
    return result/(num_locations)

"""# Extract style and content

Build a model that returns the style and content tensors.
"""

class StyleContentModel(tf.keras.models.Model):
    def __init__(self, style_layers, content_layers):
        super().__init__()
        self.vgg = vgg_layers(style_layers + content_layers)
        self.style_layers = style_layers
        self.content_layers = content_layers
        self.num_style_layers = len(style_layers)
        self.vgg_trainable = False
    
    def call(self, inputs):
        inputs = inputs * 255.0
        preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)
        outputs = self.vgg(preprocessed_input)
        style_outputs, content_outputs = (outputs[:self.num_style_layers], outputs[self.num_style_layers:])

        style_outputs = [gram_matrix(style_output)  for style_output in style_outputs]

        content_dict = {content_name:value for content_name, value in zip(self.content_layers, content_outputs)}

        style_dict = {style_name:value for style_name, value in zip(self.style_layers, style_outputs)}


        return {'content': content_dict, 'style' : style_dict}

"""When called on an image, this model returns the gram matrix (style) of the style_layers and content of the content_layers:"""

extractor = StyleContentModel(style_layers, content_layers)

results = extractor(tf.constant(content_image))

style_results = results['style']

print('Styles:')
for name, output in sorted(results['style'].items()):
    print("  ", name)
    print("    shape: ", output.numpy().shape)
    print("    min: ", output.numpy().min())
    print("    max: ", output.numpy().max())
    print("    mean: ", output.numpy().mean())
    print()

print("Contents:")
for name, output in sorted(results['content'].items()):
    print("  ", name)
    print("    shape: ", output.numpy().shape)
    print("    min: ", output.numpy().min())
    print("    max: ", output.numpy().max())
    print("    mean: ", output.numpy().mean())

"""# Run gradient descent

With this style and content extractor, you can now implement the style transfer algorithm. Do this by calculating the mean square error for your image's output relative to each target, then take the weighted sum of these losses.

Set your style and content target values:
"""

style_targets = extractor(style_image)['style']
content_targets = extractor(content_image)['content']

"""Define a tf.Variable to contain the image to optimize. To make this quick, initialize it with the content image (the tf.Variable must be the same shape as the content image):"""

image = tf.Variable(content_image)

def clip_0_1(image):
    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)

"""Paper recommendes lbfgs but Adam is fine too."""

opt = tf.keras.optimizers.Adam(lr=0.02, epsilon=1e-1)

style_weight=1e-2
content_weight=1e4

def style_content_loss(outputs):
    style_outputs = outputs['style']
    content_outputs = outputs['content']
    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) 
                           for name in style_outputs.keys()])
    style_loss *= style_weight / num_style_layers

    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) 
                             for name in content_outputs.keys()])
    
    content_loss *= content_weight / num_content_layers
    loss = style_loss + content_loss
    return loss

@tf.function
def train_step(image):
    with tf.GradientTape() as tape:
        outputs = extractor(image)
        loss = style_content_loss(outputs)
    
    grads = tape.gradient(loss, image)
    opt.apply_gradients([(grads, image)])
    image.assign(clip_0_1(image))

train_step(image)
train_step(image)
train_step(image)
tensor_to_image(image)

import time
start = time.time()

epochs = 10
steps_per_epoch = 100

step = 0
for n in range(epochs):
  for m in range(steps_per_epoch):
    step += 1
    train_step(image)
    print(".", end='')
  display.clear_output(wait=True)
  display.display(tensor_to_image(image))
  print("Train step: {}".format(step))
  
end = time.time()
print("Total time: {:.1f}".format(end-start))

"""# Improving on it

One downside to this basic implementation is that it produces a lot of high frequency artifacts. Decrease these using an explicit regularization term on the high frequency components of the image. In style transfer, this is often called the total variation loss:
"""

def high_pass_x_y(image):
  x_var = image[:,:,1:,:] - image[:,:,:-1,:]
  y_var = image[:,1:,:,:] - image[:,:-1,:,:]

  return x_var, y_var

x_deltas, y_deltas = high_pass_x_y(content_image)

plt.figure(figsize=(14,10))
plt.subplot(2,2,1)
imshow(clip_0_1(2*y_deltas+0.5), "Horizontal Deltas: Original")

plt.subplot(2,2,2)
imshow(clip_0_1(2*x_deltas+0.5), "Vertical Deltas: Original")

x_deltas, y_deltas = high_pass_x_y(image)

plt.subplot(2,2,3)
imshow(clip_0_1(2*y_deltas+0.5), "Horizontal Deltas: Styled")

plt.subplot(2,2,4)
imshow(clip_0_1(2*x_deltas+0.5), "Vertical Deltas: Styled")

"""This shows how the high frequency components have increased.

Also, this high frequency component is basically an edge-detector. You can get similar output from the Sobel edge detector, for example:
"""

plt.figure(figsize=(14,10))

sobel = tf.image.sobel_edges(content_image)
plt.subplot(1,2,1)
imshow(clip_0_1(sobel[...,0]/4+0.5), "Horizontal Sobel-edges")
plt.subplot(1,2,2)
imshow(clip_0_1(sobel[...,1]/4+0.5), "Vertical Sobel-edges")

"""The regularization loss associated with this is the sum of the squares of the values:"""

def total_variation_loss(image):
    x_deltas, y_deltas = high_pass_x_y(image)
    return tf.reduce_sum(tf.abs(x_deltas)) + tf.reduce_sum(tf.abs(y_deltas))

total_variation_loss(image).numpy()

"""That demonstrated what it does. But there's no need to implement it yourself, TensorFlow includes a standard implementation:"""

tf.image.total_variation(image).numpy()

"""# Re-Run Optimization"""

total_variation_weight=30

@tf.function
def train_step(image):
    with tf.GradientTape() as tape:
        outputs = extractor(image)
        loss = style_content_loss(outputs)
        loss += total_variation_weight * tf.image.total_variation(image)
    
    grad = tape.gradient(loss, image)
    opt.apply_gradients([(grad, image)])
    image.assign(clip_0_1(image))

image = tf.Variable(content_image)

import time
start = time.time()

epochs = 10
steps_per_epoch = 100

step = 0
for n in range(epochs):
  for m in range(steps_per_epoch):
    step += 1
    train_step(image)
    print(".", end='')
  display.clear_output(wait=True)
  display.display(tensor_to_image(image))
  print("Train step: {}".format(step))

end = time.time()
print("Total time: {:.1f}".format(end-start))

file_name = 'stylized-image.png'
tensor_to_image(image).save(file_name)