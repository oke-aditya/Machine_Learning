{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_classification_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7ekCanEGNLy",
        "colab_type": "text"
      },
      "source": [
        "# Padding and Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tneZtQZKGaVc",
        "colab_type": "text"
      },
      "source": [
        "Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzHvnuS0Gbrs",
        "colab_type": "text"
      },
      "source": [
        "- Adding zeros at end of the sequence to keep the sequence length constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DVhO14Gibr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = [\n",
        "  [\"The\", \"weather\", \"will\", \"be\", \"nice\", \"tomorrow\"],\n",
        "  [\"How\", \"are\", \"you\", \"doing\", \"today\"],\n",
        "  [\"Hello\", \"world\", \"!\"]\n",
        "]\n",
        "tokenzing = [\n",
        "  [83, 91, 1, 645, 1253, 927],\n",
        "  [73, 8, 3215, 55, 927],\n",
        "  [71, 1331, 4231]\n",
        "]\n",
        "\n",
        "padding = [[  83   91    1  645 1253  927]\n",
        " [  73    8 3215   55  927    0]\n",
        " [ 711  632   71    0    0    0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbdwR5g_GRZt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Masking\n",
        "\n",
        "- \"Masking\" is how layers are able to know when to skip / ignore certain timesteps in sequence inputs.\n",
        "- Some layers are mask-generators: Embedding can generate a mask from input values (if mask_zero=True), and so can the Masking layer.\n",
        "- Some layers are mask-consumers: they expose a mask argument in their __call__ method. This is the case for RNN layers.\n",
        "- In the Functional API and Sequential API, mask information is propagated automatically.\n",
        "- When writing subclassed models or when using layers in a standalone way, pass the mask arguments to layers manually.\n",
        "0 You can easily write layers that modify the current mask, that generate a new mask, or that consume the mask associated with the inputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s37CApNKG1Rr",
        "colab_type": "text"
      },
      "source": [
        "# Test classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC1Ce7NvGJ69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0926f5a-4b95-4136-b5e3-d20d28716507"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-_6gMSaG79z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cUQYJOlG9Cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmI4ZP6wHAC6",
        "colab_type": "text"
      },
      "source": [
        "# Load IMDB Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1nhAVPqHFKW",
        "colab_type": "text"
      },
      "source": [
        "- IMDB data is already tokenzied so we dont need to tokenize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVK1tmgKG-L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_examples, test_examples = dataset['train'], dataset['test']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkw71PeNHB7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eq2aJJUHRcX",
        "colab_type": "text"
      },
      "source": [
        "- Note: As of TensorFlow 2.2 the padded_shapes argument is no longer required. The default behavior is to pad all axes to the longest in the batch.\n",
        "\n",
        "In tf v2.2 use\n",
        "\n",
        "train_dataset = (train_examples\n",
        "                 .shuffle(BUFFER_SIZE)\n",
        "                 .padded_batch(BATCH_SIZE))\n",
        "\n",
        "test_dataset = (test_examples\n",
        "                .padded_batch(BATCH_SIZE))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_q2vX3CHQi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (train_examples.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None], [])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr498Ou0HpJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = (test_examples.padded_batch(BATCH_SIZE, padded_shapes=([None], [])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zmPHSLRHx9l",
        "colab_type": "text"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk6FG-UxIAo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = info.features['text'].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_RiNVjJHwRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(encoder.vocab_size, 64))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True, recurrent_dropout=0.2)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True, recurrent_dropout=0.2)))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhwXglBeIqOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gaCv4HdIbya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KNO06INIsJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e9a537a9-a476-4ab0-a907-87cbc9521ac3"
      },
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset, \n",
        "                    validation_steps=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "     41/Unknown - 395s 10s/step - loss: 0.7178 - accuracy: 0.4941"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG3n_Va4Iu9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ix6YGPKJHAS",
        "colab_type": "text"
      },
      "source": [
        "The above model does not mask the padding applied to the sequences. This can lead to skew if trained on padded sequences and test on un-padded sequences. Ideally you would use masking to avoid this, but as you can see below it only have a small effect on the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w880xRoLI8hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}