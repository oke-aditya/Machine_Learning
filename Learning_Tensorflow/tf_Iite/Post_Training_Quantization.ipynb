{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Post_Training_Quantization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVB0Px68TPOR",
        "colab_type": "text"
      },
      "source": [
        "# Post training Quatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tCOhAkrTRKB",
        "colab_type": "text"
      },
      "source": [
        "- We have a trained model that we want to optimize.\n",
        "- Optimizing this model by using tflite does weight pruning, adjusts the outputs and weights to int8.\n",
        "- Also tflite optimizes the size of the model in this process.\n",
        "- This is useful for low compute devices like mobiles and also useful when we are using edge devices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CKCB7dURiMA",
        "colab_type": "text"
      },
      "source": [
        "# Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7mCvVfsFWYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d70fa019-9243-408b-bd8c-5406d9f24b92"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTsFstr9RnNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzJ_oxA5RkH2",
        "colab_type": "text"
      },
      "source": [
        "# Load the old Model which was trained Unquantized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6RDgpdERmWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unqunatized_model = tf.keras.models.load_model('/content/fashion_unquantized_model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOQysk93R1O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unqunatized_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kawIryYR9XH",
        "colab_type": "text"
      },
      "source": [
        "# Use Tflite to convert the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfZJXk0uR2Qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(unqunatized_model)\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sobPhUN4SLHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "50d017d4-1153-48ca-d6ae-fef93e845003"
      },
      "source": [
        "model_size = len(tflite_model) / 1024\n",
        "print(\"Model size = %d KBs\"%(model_size))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 679 KBs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYRRXULMSWA4",
        "colab_type": "text"
      },
      "source": [
        "# We can set several optimizations also"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yAZz9HBSS2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
        "# DEFAULT IS FLOAT 16 format for quantization.\n",
        "# We need a dataset_gen once to check for data.\n",
        "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# converter.inference_input_type = tf.uint8\n",
        "# converter.inference_output_type = tf.uint8\n",
        "# converter.representative_dataset = dataset_gen\n",
        "tflite_quantized_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mryOKe30Sy9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "43f45565-05fd-49f4-9c83-9d8979aba941"
      },
      "source": [
        "model_size = len(tflite_quantized_model) / 1024\n",
        "print(\"Model size = %d KBs\"%(model_size))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 175 KBs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdg4MomfS6sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# converter.inference_input_type = tf.uint8\n",
        "# converter.inference_output_type = tf.uint8\n",
        "# converter.representative_dataset = dataset_gen\n",
        "tflite_tiny_quantized_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXJd2YYqTAxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4121d16d-4fbe-42e4-8903-a1a204bf982d"
      },
      "source": [
        "model_size = len(tflite_tiny_quantized_model) / 1024\n",
        "print(\"Model size = %d KBs\"%(model_size))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 175 KBs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF7ngebcTmV7",
        "colab_type": "text"
      },
      "source": [
        "# Check on the dataset once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YecskW1TDv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "fe16f263-41ee-4788-c039-550c0f47a13d"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiz8WoAkUCQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "23b3abd6-1faf-4bc0-c102-f2d2367baf94"
      },
      "source": [
        "print(x_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9hzURSuUFYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6fc127f2-b5e6-4f18-ba10-2106eeff7a75"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO6MfFZ6UHFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = np.expand_dims(x_test, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9DgqYouU-wQ",
        "colab_type": "text"
      },
      "source": [
        "# Invoke the interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ91oiCHUOJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lULIIi-tgdW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter.get_tensor_details()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziydCggogf1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_layers = interpreter.get_tensor_details()\n",
        "for layer in all_layers:\n",
        "    print(interpreter.get_tensor(layer[\"index\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzTjOyyCfy5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6li81ycvgp_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_output = []\n",
        "for test_image in x_test:\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_tensor_index, test_image)\n",
        "    interpreter.invoke()\n",
        "    out = np.argmax(output()[0])\n",
        "\n",
        "    prediction_output.append(out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzcA3n9Ajovx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accurate_count = 0\n",
        "for index in range(len(prediction_output)):\n",
        "    if prediction_output[index] == y_test[index]:\n",
        "        accurate_count += 1\n",
        "    \n",
        "    accuracy = accurate_count / len(prediction_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36IM1HvdktIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "43a1ee62-250a-4b8b-a3dd-ebbe33aa9bd8"
      },
      "source": [
        "print(accuracy)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNxgX800mTIw",
        "colab_type": "text"
      },
      "source": [
        "# Time It"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGh1GHNTmT-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1c015f11-b680-469e-ffe3-8fe67e08d209"
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for test_image in x_test:\n",
        "    test_image = np.expand_dims(test_image, axis=0)\n",
        "    model.predict(test_image)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Total time for prediction with normal model = %d seconds\" %(end_time - start_time))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time for prediction with normal model = 255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M58iCk51mrEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "968ac8f7-1a8a-4e57-ad7d-aa2698f45ef6"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for test_image in x_test:\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "\n",
        "    interpreter.set_tensor(input_tensor_index, test_image)\n",
        "    interpreter.invoke()\n",
        "    out = np.argmax(output()[0])\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Total time for prediction with normal model = %d seconds\" %(end_time - start_time))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time for prediction with normal model = 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXmzUZOgoh-N",
        "colab_type": "text"
      },
      "source": [
        "# Gist of what you should do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxSMFLfxoqOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make tflite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(unqunatized_model)\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgduTCehn8Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the interpreter\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3u1kad1ouev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set i/o for the interpreter\n",
        "input_tensor_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTrQMKf8o5Md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the output\n",
        "for test_image in x_test:\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "\n",
        "    interpreter.set_tensor(input_tensor_index, test_image)\n",
        "    interpreter.invoke()\n",
        "    out = np.argmax(output()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}