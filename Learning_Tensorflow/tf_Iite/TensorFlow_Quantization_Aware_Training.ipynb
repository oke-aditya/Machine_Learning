{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_Quantization_Aware_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE7XzjrPKYFk",
        "colab_type": "text"
      },
      "source": [
        "# Quantization Aware Training Using Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uinQ0vIkKbhc",
        "colab_type": "text"
      },
      "source": [
        "- This creates a model which is already quantized.\n",
        "- This is opposite to post model quantization where we prune the weights of the model after training.\n",
        "- Here we train a model that already knows what quantized weights are.\n",
        "- It does reduced precision training.\n",
        "- Advantage over post model is accuracy. Model is qunatization aware so it is better than post quantization.\n",
        "- It does integer arithmetic, so it is pretty fast with CPU.\n",
        "- Train on GPU infer of CPU.\n",
        "- Useful for edge Devices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRNWJ3AKR9Tp",
        "colab_type": "text"
      },
      "source": [
        "# GET THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMwZbV3cKGU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg5M0ZA9LvMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc3ZbThZMXXX",
        "colab_type": "code",
        "outputId": "281c88cd-00e9-4c14-c194-79a3c24f1224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "import datetime"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPOmRCzvMi4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.config.list_physical_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-OfMRQQP5Z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset, info = tfds.load(name=\"fashion_mnist\", with_info=True, as_supervised=True, try_gcs=True, split=[\"train\", \"test\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw2SCiy5QI4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "fc551596-46b0-4d4f-d4c2-b1bd72089c9c"
      },
      "source": [
        "print(info.features)\n",
        "print(info.features[\"label\"].num_classes)\n",
        "print(info.features[\"label\"].names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FeaturesDict({\n",
            "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "})\n",
            "10\n",
            "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxhIjC2xRLC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fm_train, fm_test = dataset[0], dataset[1]\n",
        "fm_val = fm_test.take(30000)\n",
        "fm_test = fm_test.skip(30000).take(30000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVkBRuOWRWAG",
        "colab_type": "code",
        "outputId": "fe44175f-6279-4f96-b981-61a70c3e8574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# print(len(list(fm_train)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13yLlIHoR_X_",
        "colab_type": "text"
      },
      "source": [
        "# Inspect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNwNq_tZRa0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for fm_sample in fm_train.take(5):\n",
        "    image, label = fm_sample[0], fm_sample[1]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image.numpy()[:, :, 0].astype(np.float32), cmap=\"gray\") \n",
        "    print(\"Label %d \" %label.numpy())\n",
        "    print(\"Category %s \"%info.features[\"label\"].names[label.numpy()])\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzBP5Z91Sy9H",
        "colab_type": "text"
      },
      "source": [
        "# Get THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTJjAQgYSbpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale(img, label):\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img /= 255.\n",
        "    return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoDRiyXeSw8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(batch_size=32):\n",
        "    train_dataset_scaled = fm_train.map(scale).shuffle(60000).batch(batch_size)\n",
        "    test_dataset_scaled = fm_test.map(scale).batch(batch_size)\n",
        "    val_dataset_scaled = fm_val.map(scale).batch(batch_size)\n",
        "\n",
        "    return train_dataset_scaled, test_dataset_scaled, val_dataset_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKLDbSFETNXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(64, 2, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "    model.add(tf.keras.layers.MaxPooling2D())\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, 2, padding=\"same\", activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.MaxPooling2D())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, 2, padding=\"same\", activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.MaxPooling2D())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4naYIDiDWrS",
        "colab_type": "text"
      },
      "source": [
        "# Unquantized Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjeOEMZ1DWcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unquantized_model = create_model()\n",
        "unquantized_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN7qQpbZDjYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset, test_dataset, val_dataset = get_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HmYivH4Dk32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6e8e2ab1-3528-44cc-c088-006dd9657b17"
      },
      "source": [
        "train_dataset.cache()\n",
        "val_dataset.cache()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JJK-AsLDfyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b5c6ff2a-bc5c-4666-e509-29ea088fb098"
      },
      "source": [
        "unquantized_model.fit(train_dataset, epochs=5, validation_data=val_dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.6255 - acc: 0.7677 - val_loss: 0.3747 - val_acc: 0.8629\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4099 - acc: 0.8516 - val_loss: 0.3107 - val_acc: 0.8876\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3582 - acc: 0.8697 - val_loss: 0.2835 - val_acc: 0.8989\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3310 - acc: 0.8795 - val_loss: 0.2822 - val_acc: 0.8974\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3158 - acc: 0.8857 - val_loss: 0.2784 - val_acc: 0.9003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb960344518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flKZFF47Doey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unquantized_model.save(\"fashion_unquantized_model.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsvkTBgiUjip",
        "colab_type": "text"
      },
      "source": [
        "# Quantize The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2oQvCV-UHsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_model_optimization as tfmot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U68B6F16Ueo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hElzGZwqUgr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantized_model = tfmot.quantization.keras.quantize_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7F3xZRlUq7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantized_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s74nT0jAU6Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantized_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciLydwb1U8JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = os.path.join(\"/tmp/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghsHvNiUVru7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset, test_dataset, val_dataset = get_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t5x4OD_Wx7n",
        "colab_type": "code",
        "outputId": "9c2e3b0d-8ad6-4f7d-81e0-d0a78b51d636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "train_dataset.cache()\n",
        "val_dataset.cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnvNfCflW11O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = quantized_model.fit(train_dataset, epochs=5, validation_data=val_dataset, callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmFCUl6IXt6E",
        "colab_type": "text"
      },
      "source": [
        "- Still after training the output is float 32 weights.\n",
        "\n",
        "- It is just aware of Quantization. We still need to quantize it so that it will be in int.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-egCoIHXA_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/tmp/fashion_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NxCsNKTZspw",
        "colab_type": "text"
      },
      "source": [
        "# Check the tensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE6MLJm0Z1Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbJS9cUrZSMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir /tmp/logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYCOz8YuZyTp",
        "colab_type": "code",
        "outputId": "27c26b9a-db79-4aa1-bea0-4aed5d5e25c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May 15 14:17:17 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    43W / 250W |    855MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D8tucuqacmW",
        "colab_type": "code",
        "outputId": "c98b04fc-0f6b-40c2-c291-8052e3ef56e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(quantized_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fcbb6fbdac8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhLEo-T5aWoj",
        "colab_type": "code",
        "outputId": "7eae5cb5-e6ac-4ddc-abf5-ef8f870a47ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "quantized_model.evaluate(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1672 - acc: 0.9384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1671743094921112, 0.9384166598320007]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6gs-527aOKk",
        "colab_type": "code",
        "outputId": "2b06071f-e9f2-42ac-a497-3e4b4f7d1bf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "quantized_model.evaluate(val_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2443 - acc: 0.9124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2442520260810852, 0.9124000072479248]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjOEwQ8Fa3LT",
        "colab_type": "text"
      },
      "source": [
        "# Quantize it Fully"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX0mhze2avfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(quantized_model)\n",
        "converter_optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLySukhYbNYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantized_tflite_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iprkTSHobRPP",
        "colab_type": "code",
        "outputId": "4393cd22-8e61-410d-e152-5515695fce69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "quantized_model_size = len(quantized_tflite_model) / 1024\n",
        "print(\"Size of quantized model %d KBs\"%(quantized_model_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of quantized model 681 KBs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka2U0bdCb69T",
        "colab_type": "text"
      },
      "source": [
        "# Infer on the Qunatized Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coixLuaAbdzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wAq8dZPcLUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-LTOtWecXX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter.get_tensor_details()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW4HqdJKca3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_output = []\n",
        "accurate_count = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEuVAylKdJiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for test_image in fm_val.map(scale):\n",
        "    # print(\"Hi wWT\")\n",
        "    test_image_p = np.expand_dims(test_image[0], axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_tensor_index, test_image_p)\n",
        "\n",
        "    interpreter.invoke()\n",
        "    out = np.argmax(output_index()[0])\n",
        "    prediction_output.append(out)\n",
        "    # print(out)\n",
        "\n",
        "    if out == int(test_image[1].numpy()):\n",
        "        accurate_count += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLMiP91NwHvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = accurate_count / len(prediction_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td-mcsJvraUy",
        "colab_type": "code",
        "outputId": "0cf54857-a8fe-4d6f-84eb-ca6f3eb48bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(\"Accuracy = %0.4f \"%(accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 91.2500 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}