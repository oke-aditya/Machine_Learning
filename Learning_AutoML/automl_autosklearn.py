# -*- coding: utf-8 -*-
"""AutoML_AutoSklearn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ykYX4EDuWeMKS91YVIxHNmBfGUYRclDa

# Auto Sklearn

## Installing

- NOTE: -

WINDOWS
- auto-sklearn relies heavily on the Python module resource. resource is part of Pythonâ€™s Unix Specific Services and not available on a Windows machine. Therefore, it is not possible to run auto-sklearn on a Windows machine.

MAC OS X
- We currently do not know if auto-sklearn works on OSX. There are at least two issues holding us back from actively supporting OSX

LINUX
- use the below way
"""

!sudo apt-get install build-essential swig
!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install
!pip install auto-sklearn

"""## Time to Use"""

import sys,tempfile, urllib, os
import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np

BASE_DIR = '/tmp'
OUTPUT_FILE = os.path.join(BASE_DIR, 'churn_data.csv')

churn_data=urllib.request.urlretrieve('https://raw.githubusercontent.com/srivatsan88/YouTubeLI/master/dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv', OUTPUT_FILE)

churn_df = pd.read_csv(OUTPUT_FILE)

churn_df.head()

churn_df['Churn'].value_counts()

"""# Data Cleaning 

- Ahem, Ahem. Auto Sklearn will not clean the data for you.
- You need to clean it yourself.
- You need to convert string data to numerical values.
- It will not accept string values. Nor will it handle it.
"""

churn_df = churn_df.replace(r'^\s*$', np.nan, regex=True)

churn_df.head()

churn_df.iloc[: ,19] = pd.to_numeric(churn_df.iloc[:, 19], errors='coerce')

churn_df.head()

from sklearn.impute import SimpleImputer
imp_median = SimpleImputer(missing_values=np.nan, strategy='median')

churn_df.iloc[:, 19] = imp_median.fit_transform(churn_df.iloc[:, 19].values.reshape(-1, 1))

from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OrdinalEncoder

categorical_columns = ['gender', 'Partner', 'Dependents','PhoneService','MultipleLines','InternetService',
                       'OnlineSecurity','OnlineBackup','DeviceProtection',
                       'TechSupport','StreamingTV','StreamingMovies','Contract','PaperlessBilling','PaymentMethod','Churn']

column_trans = make_column_transformer((OrdinalEncoder(), categorical_columns))

churn_transformed = column_trans.fit_transform(churn_df)

churn_df_trans = churn_df.copy()
churn_df_trans = pd.DataFrame(churn_transformed, columns=categorical_columns).astype(int)

churn_df.update(churn_df_trans)

churn_df.head()

churn_df_y = pd.DataFrame(churn_df['Churn'])
churn_df_x = churn_df.drop(['Churn'], axis=1, inplace=False)

churn_df_y['Churn'] = churn_df_y['Churn'].astype(np.int32)

churn_df_x.drop(['customerID'], axis=1, inplace=True)

for cols in churn_df_x.columns:
    churn_df_x[cols] = churn_df_x[cols].astype(np.float32)

X_train, X_test, y_train, y_test = train_test_split(churn_df_x, churn_df_y, train_size=0.75, test_size=0.25, stratify=churn_df_y, random_state=31)

"""# Using the autosklearn module"""

import autosklearn.classification

"""Parameters to give
- time_left_for_task = time given for auto ml to do its job
- include estimators = algos that you want to execute
- exclude estimators = algos that you want to exclude
- include_preprocessors = denotes the preprocessing such as PCA. It does not preprocess the data like encoding or as such.
- per_run_time_limit = time limit per algorithm run.
- n_jobs = no of parallel processing threads that are required.
- exclude_preprocessirs = preprocessors that we do not want to take.
"""

clf = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=120, per_run_time_limit=30, n_jobs=2,
    include_estimators=["random_forest", "sgd", ], exclude_estimators=None, include_preprocessors=["no_preprocessing", ], exclude_preprocessors=None)

clf.fit(X_train, y_train)

# Shows statistics about models trained
print(clf.show_models())

print(clf.sprint_statistics())

clf.cv_results_['params'][np.argmax(clf.cv_results_['mean_test_score'])]

predictions = clf.predict(X_test)

from sklearn.metrics import accuracy_score

print("Accuracy score : %s" %(accuracy_score(y_test, predictions)))

"""# Validating"""

from sklearn.metrics import confusion_matrix, precision_score, recall_score

print(confusion_matrix(y_test, predictions))

import seaborn as sns
import matplotlib.pyplot as plt

sns.set()

sns.heatmap(pd.DataFrame(confusion_matrix(y_test, predictions)), annot=True, annot_kws={"size": 16}, fmt='')
plt.show()

print(precision_score(y_test, predictions))

print(recall_score(y_test, predictions))

"""# Dumping using Pickle"""

import pickle

x = clf.show_models()

# Dumps the ensemble of models
my_model = {"ensemble" : x}

pickle.dump(my_model, open("model.pickle", 'wb'))

!ls *.pickle

