# -*- coding: utf-8 -*-
"""AutoML_AutoViML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k7YuK1oRjASiRMMKwuDxmF-i1SSNvMzk

# Using AutoViML for AutoML

- It takes care of categorical encoding.
- Takes care of feature selection.
- It provides graphical outputs that can explain the model.
- Gives multiple graphs like AUC curve etc.
- Does a bit of data cleaning.
- It tunes the hyperparamters as well.

# Installing AutoViML
"""

! pip install autoviml

! pip install shap
# For model explainability

"""# Time to use it

## Loading Data
"""

import sys,tempfile, urllib, os
import pandas as pd

BASE_DIR = '/tmp'
OUTPUT_FILE = os.path.join(BASE_DIR, 'churn_data.csv')

churn_data=urllib.request.urlretrieve('https://raw.githubusercontent.com/srivatsan88/YouTubeLI/master/dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv', OUTPUT_FILE)

churn_df = pd.read_csv(OUTPUT_FILE)

churn_df.head()

# Splitting it into train and test 
size = int(0.7 * churn_df.shape[0])
train_df = churn_df[:size]
test_df = churn_df[size:]

"""## Time for AutoViML"""

from autoviml.Auto_ViML import Auto_ViML

target = 'Churn'

"""hyper_param: Tuning options are GridSearch ('GS') and RandomizedSearch ('RS'). Default is 'GS'.

feature_reduction: Default = 'True' but it can be set to False if you don't want automatic    

Boosting Flag: you have 4 possible choices (default is False):                               
  None = This will build a Linear Model                                                  
  False = This will build a Random Forest or Extra Trees model (also known as Bagging)        
  True = This will build an XGBoost model                                                     
  CatBoost = THis will build a CatBoost model (provided you have CatBoost installed)
"""

model, features, trainm, testm = Auto_ViML(train_df, target, test_df,
                            sample_submission='',
                            scoring_parameter='', KMeans_Featurizer=False,
                            hyper_param='GS',feature_reduction=True,
                             Boosting_Flag=None,Binning_Flag=False,
                            Add_Poly=0, Stacking_Flag=False,Imbalanced_Flag=False,
                            verbose=1)

features

trainm

testm

from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(test_df[target].values, testm['Churn_Bagging_predictions'].values))

print(confusion_matrix(test_df[target].values, testm['Churn_Ensembled_predictions'].values))

print(confusion_matrix(test_df[target].values, testm['Churn_Boosting_predictions'].values))

print(classification_report(test_df[target].values, testm['Churn_Boosting_predictions'].values))