{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# 1-D Convonets"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Introduction"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"- 1-D convonents can be used for text data.\n- They are faster than RNNs and at times more useful for audio / signal processing."},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"- Such 1D convolution layers can recognize local patterns in a sequence. Because the\nsame input transformation is performed on every patch, a pattern learned at a certain\nposition in a sentence can later be recognized at a different position, making 1D convnets\ntranslation invariant (for temporal translations). \n- For instance, a 1D convnet processing\nsequences of characters using convolution windows of size 5 should be able to\nlearn words or word fragments of length 5 or less"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"- The 2D poolingm operation has a 1D equivalent: extracting 1D patches (subsequences) from an input\nand outputting the maximum value (max pooling) or average value (average pooling).\n- Just as with 2D convnets, this is used for reducing the length of 1D inputs (subsampling)."},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Working with IMDB"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"from keras.datasets import imdb\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras import optimizers"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"max_features = 1000       # Consider only top 1000 words as features\nmax_len = 500             # Maximum length of review 500"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Number of reviews in train = 25000\nNumber of reviews in test = 25000\n"}],"source":"print(\"Number of reviews in train = %d\" %(len(x_train)))\nprint(\"Number of reviews in test = %d\" %(len(x_test)))"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"x_padded_train = sequence.pad_sequences(x_train, maxlen = max_len)\nx_padded_test = sequence.pad_sequences(x_test, maxlen= max_len)"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## Tips for using 1D Convonets"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"- 1D convnets are structured in the same way as their 2D counterparts, which you used\nin chapter 5: they consist of a stack of Conv1D and MaxPooling1D layers, ending in\neither a global pooling layer or a Flatten layer, that turn the 3D outputs into 2D outputs,\nallowing you to add one or more Dense layers to the model for classification or\nregression.\n- One difference, though, is the fact that you can afford to use larger convolution\nwindows with 1D convnets. \n- With a 2D convolution layer, a 3 × 3 convolution window\ncontains 3 × 3 = 9 feature vectors; but with a 1D convolution layer, a convolution window\nof size 3 contains only 3 feature vectors. \n- You can thus easily afford 1D convolution windows of size 7 or 9."},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"model = Sequential()\nmodel.add(layers.Embedding(max_features, 128, input_length=max_len))\nmodel.add(layers.Conv1D(32, kernel_size=7, activation='relu'))\nmodel.add(layers.MaxPool1D(5))\nmodel.add(layers.Conv1D(32, kernel_size=7, activation='relu'))\nmodel.add(layers.GlobalMaxPool1D())\nmodel.add(layers.Dense(1))\n"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"opt = optimizers.Adam(lr = 0.001, decay=1e-5)\nmodel.compile(optimizer =  opt, loss = 'binary_crossentropy', metrics=['acc'])"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 500, 128)          128000    \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 494, 32)           28704     \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 92, 32)            7200      \n_________________________________________________________________\nglobal_max_pooling1d_1 (Glob (None, 32)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 163,937\nTrainable params: 163,937\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":"model.summary()"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Train on 25000 samples, validate on 25000 samples\nEpoch 1/2\n25000/25000 [==============================] - 130s 5ms/step - loss: 0.6560 - acc: 0.6531 - val_loss: 0.5343 - val_acc: 0.7648\nEpoch 2/2\n25000/25000 [==============================] - 133s 5ms/step - loss: 0.4605 - acc: 0.8052 - val_loss: 0.4623 - val_acc: 0.8074\n"}],"source":"history = model.fit(x_padded_train, y_train, validation_data=(x_padded_test, y_test) ,epochs = 2, batch_size=32, verbose = 1)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}