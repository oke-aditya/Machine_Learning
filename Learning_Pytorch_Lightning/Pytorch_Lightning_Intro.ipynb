{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Lightning_Intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEeaklf-CB3b",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Lightning Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq-UvogYCJCo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Define the lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAXHaVpOAy9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_rZpdpdCQQq",
        "colab_type": "code",
        "outputId": "8768a68c-94ab-44f9-ddca-3f87ea83ed36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install -q pytorch-lightning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 256kB 2.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 4.3MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byt762PBCRw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_lightning.core.lightning import LightningModule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPMY3Et0Chfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class litmodel(LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(28 * 28, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        tensorboard_logs = {\"train_loss\" : loss}\n",
        "        return {\"loss\" : loss, \"log\" : tensorboard_logs}\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        dataset = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())\n",
        "        loader = DataLoader(dataset, batch_size=32, num_workers=4, shuffle=True)\n",
        "        return loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAEE9NQbDkzV",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Fit with a Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky9H96toDin1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_lightning import Trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVih9Hd7DnI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = litmodel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2ai0dkcDo2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# most basic trainer, uses good defaults\n",
        "trainer = Trainer(gpus=1, num_nodes=1, max_epochs=3)\n",
        "trainer.fit(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJtRwPgMEJ60",
        "colab_type": "text"
      },
      "source": [
        "The beauty of Lightning is that it handles the details of when to validate, when to call .eval(), turning off gradients, detaching graphs, making sure you don’t enable shuffle for val, etc…"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpuLdXqRGyxX",
        "colab_type": "text"
      },
      "source": [
        "# Validation loop and Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2LGsaC5D04E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class litmodel(LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(28 * 28, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        tensorboard_logs = {\"train_loss\" : loss}\n",
        "        return {\"loss\" : loss, \"log\" : tensorboard_logs}\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        dataset = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())\n",
        "        loader = DataLoader(dataset, batch_size=32, num_workers=4, shuffle=True)\n",
        "        return loader\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        y_hat = self(x)\n",
        "        return {\"val_loss\" : F.cross_entropy(y_hat, y)}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        tensorboard_logs = {'val_loss': avg_loss}\n",
        "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        dataset = MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor())\n",
        "        loader = DataLoader(dataset, batch_size=32, num_workers=4)\n",
        "        return loader\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        return {\"test_loss\" : F.cross_entropy(y_hat, y)}\n",
        "    \n",
        "    def test_eopch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
        "        tensorboard_logs = {'test_loss': avg_loss}\n",
        "        return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n",
        "    \n",
        "    def test_loader(self):\n",
        "        dataset = MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor())\n",
        "        loader = DataLoader(dataset, batch_size=32, num_workers=4)\n",
        "        return loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y_gs15PJYgR",
        "colab_type": "text"
      },
      "source": [
        " However, this time you need to specifically call test (this is done so you don’t use the test set by mistake)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsuxwlOfJiie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = litmodel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L-6h2P2LJdeY",
        "colab": {}
      },
      "source": [
        "# most basic trainer, uses good defaults\n",
        "trainer = Trainer(gpus=1, num_nodes=1, max_epochs=3)\n",
        "trainer.fit(model)\n",
        "trainer.test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhTdOR6eQeUI",
        "colab_type": "text"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkbtVkyQQqkd",
        "colab_type": "text"
      },
      "source": [
        "If you don’t want to define the datasets as part of the LightningModule, just pass them into fit instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z09Zz82PJa6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=32, num_workers=4)\n",
        "# val_dataloader, test_dataloader = \n",
        "trainer = Trainer(gpus=1, num_nodes=1)\n",
        "trainer.fit(model, train_dataloader, val_dataloader)\n",
        "trainer.test(test_dataloder=test_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIHqTkCZRAdT",
        "colab_type": "text"
      },
      "source": [
        "The advantage of this method is the ability to reuse models for different datasets. The disadvantage is that for research it makes readability and reproducibility more difficult. \n",
        "\n",
        "This is why we recommend to define the datasets in the LightningModule if you’re doing research, but use the method above for production models or for prediction tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7X_Yn4VR6XU",
        "colab_type": "text"
      },
      "source": [
        "# Why Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xh7UiqpR-Ij",
        "colab_type": "text"
      },
      "source": [
        "Notice the code above has nothing about .cuda() or 16-bit or early stopping or logging, etc… This is where Lightning adds a ton of value.\n",
        "\n",
        "Without changing a SINGLE line of your code, you can now do the following with the above code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE2Lqsd1Q91a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train on TPUs using 16 bit precision with early stopping\n",
        "# using only half the training data and checking validation every quarter of a training epoch\n",
        "trainer = Trainer(\n",
        "    tpu_cores=8,\n",
        "    precision=16,\n",
        "    early_stop_checkpoint=True,\n",
        "    train_percent_check=0.5,\n",
        "    val_check_interval=0.25\n",
        ")\n",
        "\n",
        "# train on 256 GPUs\n",
        "trainer = Trainer(\n",
        "    gpus=8,\n",
        "    num_nodes=32\n",
        ")\n",
        "\n",
        "# train on 1024 CPUs across 128 machines\n",
        "trainer = Trainer(\n",
        "    num_processes=8,\n",
        "    num_nodes=128\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_jvBCHcSFbF",
        "colab_type": "text"
      },
      "source": [
        "And the best part is that your code is STILL just PyTorch… meaning you can do anything you would normally do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlQF6nNKSB28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LitModel()\n",
        "model.eval()\n",
        "\n",
        "y_hat = model(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHJpyDjGSIzC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Summary\n",
        "\n",
        "In short, by refactoring your PyTorch code:\n",
        "\n",
        "    You STILL keep pure PyTorch.\n",
        "\n",
        "    You DON’t lose any flexibility.\n",
        "\n",
        "    You can get rid of all of your boilerplate.\n",
        "\n",
        "    You make your code generalizable to any hardware.\n",
        "\n",
        "    Your code is now readable and easier to reproduce (ie: you help with the reproducibility crisis).\n",
        "\n",
        "    Your LightningModule is still just a pure PyTorch module.\n",
        "\n"
      ]
    }
  ]
}