{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost_DART.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nHsXRsxWbr_",
        "colab_type": "text"
      },
      "source": [
        "# DART: Dropouts meet Multiple Additive Regression Trees.\n",
        "\n",
        "- http://proceedings.mlr.press/v38/korlakaivinayak15.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lca3XcvXNHi",
        "colab_type": "text"
      },
      "source": [
        "## Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5sJWSe2XPkC",
        "colab_type": "text"
      },
      "source": [
        "- Drop trees in order to solve the over-fitting.\n",
        "\n",
        "- Trivial trees (to correct trivial errors) may be prevented.\n",
        "\n",
        "Because of the randomness introduced in the training, expect the following few differences:\n",
        "\n",
        "- Training can be slower than gbtree because the random dropout prevents usage of the prediction buffer.\n",
        "\n",
        "- The early stop might not be stable, due to the randomness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CIfjHVXibX",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRFOe8UmYB08",
        "colab_type": "text"
      },
      "source": [
        "- The booster DART inherits gbtree booster, so it supports all parameters that gbtree does, such as eta, gamma, max_depth etc.\n",
        "\n",
        "Additional parameters are noted below:\n",
        "\n",
        "sample_type: type of sampling algorithm.\n",
        "\n",
        "- uniform: (default) dropped trees are selected uniformly.\n",
        "\n",
        "- weighted: dropped trees are selected in proportion to weight.\n",
        "\n",
        "normalize_type: type of normalization algorithm.\n",
        "\n",
        "- tree: (default) New trees have the same weight of each of dropped trees.\n",
        "\n",
        "- forest: New trees have the same weight of sum of dropped trees (forest).\n",
        "\n",
        "rate_drop: dropout rate.\n",
        "\n",
        "- range: [0.0, 1.0]\n",
        "\n",
        "skip_drop: probability of skipping dropout.\n",
        "\n",
        "- If a dropout is skipped, new trees are added in the same manner as gbtree.\n",
        "\n",
        "- range: [0.0, 1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g3WcX5eX7E6",
        "colab_type": "text"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86KXS5UVX6rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji9ErB-MWKsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtrain = xgb.DMatrix('demo/data/agaricus.txt.train')\n",
        "dtest = xgb.DMatrix('demo/data/agaricus.txt.test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YEd4O1kYhC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify paramters via a dict (map)\n",
        "param = {'booster': 'dart',\n",
        "         'max_depth' : 5,\n",
        "         'learning_rate' : 0.1,\n",
        "         'objective' : 'binary:logistic',\n",
        "         'sample_type' : 'uniform',\n",
        "         'normalize_type' : 'tree',\n",
        "         'rate_drop' : 0.2,\n",
        "         'skip_drop' : 0.4\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgY50IhuZC4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_rounds = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt-qeRr2ZSrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bst = xgb.train(params = param, dtrain = dtrain, num_boost_round = num_rounds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Nu5w1PZjht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make prediction\n",
        "# ntree_limit must not be 0\n",
        "preds = bst.predict(dtest, ntree_limit = num_rounds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyrUjZBqhDtw",
        "colab_type": "text"
      },
      "source": [
        "## Note\n",
        "\n",
        "- Specify ntree_limit when predicting with test sets\n",
        "\n",
        "- By default, bst.predict() will perform dropouts on trees. To obtain correct results on test sets, disable dropouts by specifying a nonzero value for ntree_limit."
      ]
    }
  ]
}